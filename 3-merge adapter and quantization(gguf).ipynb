{"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"342da0cbc8f14b2ba99b3d2f6e2e91d4":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_f4539c1a9d284ea79b714291f518f85e","IPY_MODEL_a4db71875cc3421599ca0ddfc61790ee","IPY_MODEL_ff29927c978d4d868e45aaf6f94d03e6","IPY_MODEL_c8250a4ff49743089c4386a60a948d36"],"layout":"IPY_MODEL_865e8ce5389443e8b9dfc75dec621cad"}},"497fa99e4f744730aa6e151884381d5e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bd3fe2decfa049239396fc826d54269d","placeholder":"​","style":"IPY_MODEL_f9e31cd9cdad40ea87b2093a2c608336","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"b962fd5b51e84295b511a63320a4b0b8":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_222b2df734774c78b77de46e6d647cb7","placeholder":"​","style":"IPY_MODEL_91dc76fdd5c74b1fa03b8aabd08af1a3","value":""}},"f811072481ad41a5b52817a0291df1a1":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_a4210d8155b64656a3c84f3908568255","style":"IPY_MODEL_f31d73ef9147439a84034e55089440e1","value":true}},"253b3dee1cb9456dbcf91c1daf6a0dc4":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_8ffe303e94eb4af5b18891522d2e8a43","style":"IPY_MODEL_01061c93a0604988b13a1115c45d3b51","tooltip":""}},"45fbc916594e4daab09421fe5d95e416":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f911253d429047399677f11c639aefc1","placeholder":"​","style":"IPY_MODEL_31913fca0bef4e32a632134a0aeb2512","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"865e8ce5389443e8b9dfc75dec621cad":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"bd3fe2decfa049239396fc826d54269d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9e31cd9cdad40ea87b2093a2c608336":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"222b2df734774c78b77de46e6d647cb7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"91dc76fdd5c74b1fa03b8aabd08af1a3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a4210d8155b64656a3c84f3908568255":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f31d73ef9147439a84034e55089440e1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8ffe303e94eb4af5b18891522d2e8a43":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"01061c93a0604988b13a1115c45d3b51":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"f911253d429047399677f11c639aefc1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"31913fca0bef4e32a632134a0aeb2512":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c01db764e6a4291b6cd6592fbebb706":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e779786c10b843ea862600781db64313","placeholder":"​","style":"IPY_MODEL_9172bbd39a4c4ff4aa794a6e5818d21a","value":"Connecting..."}},"e779786c10b843ea862600781db64313":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9172bbd39a4c4ff4aa794a6e5818d21a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4539c1a9d284ea79b714291f518f85e":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_03d8e9eb958b4ddca60fd735ae464c9d","placeholder":"​","style":"IPY_MODEL_f1c9c23874804669850d29c94504c635","value":"Token is valid (permission: write)."}},"a4db71875cc3421599ca0ddfc61790ee":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c82effc3a4894083acf579b311262d2d","placeholder":"​","style":"IPY_MODEL_5185ec2adb884c18b58d9688bb7b24e4","value":"Your token has been saved in your configured git credential helpers (store)."}},"ff29927c978d4d868e45aaf6f94d03e6":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5964496e744e44b0a88ed54f51b81b13","placeholder":"​","style":"IPY_MODEL_5df792c9f7d04277a4c4eac84111939a","value":"Your token has been saved to /root/.cache/huggingface/token"}},"c8250a4ff49743089c4386a60a948d36":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45042afffd8d48c79c2bb58db476bfbd","placeholder":"​","style":"IPY_MODEL_a0de1924ea1f410aae857b5fe59c9822","value":"Login successful"}},"03d8e9eb958b4ddca60fd735ae464c9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1c9c23874804669850d29c94504c635":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c82effc3a4894083acf579b311262d2d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5185ec2adb884c18b58d9688bb7b24e4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5964496e744e44b0a88ed54f51b81b13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5df792c9f7d04277a4c4eac84111939a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"45042afffd8d48c79c2bb58db476bfbd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0de1924ea1f410aae857b5fe59c9822":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"465bf7c1f6c0423eaf1f8138354433b3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f48928ade2244c95b7f5cb4a445a7237","IPY_MODEL_17103cef13034b23a38859f62df8fab5","IPY_MODEL_18240277f2e9473aa5290aff38110a56"],"layout":"IPY_MODEL_e9e9bd528bfe485bb228abe7dd2f4e37"}},"f48928ade2244c95b7f5cb4a445a7237":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ab110a027254342bef333f6dd437c8c","placeholder":"​","style":"IPY_MODEL_5d5823055dff474d85003d25e8bd1485","value":"config.json: 100%"}},"17103cef13034b23a38859f62df8fab5":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_3c9993db029a4a9485b0898cd54c40a3","max":614,"min":0,"orientation":"horizontal","style":"IPY_MODEL_be14d46a73c94a53a90c754f124723be","value":614}},"18240277f2e9473aa5290aff38110a56":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2f6e014f45f144e0b0919a6109af6ec5","placeholder":"​","style":"IPY_MODEL_0b41609b2dee43d8b0b8ff138480784e","value":" 614/614 [00:00&lt;00:00, 29.6kB/s]"}},"e9e9bd528bfe485bb228abe7dd2f4e37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ab110a027254342bef333f6dd437c8c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d5823055dff474d85003d25e8bd1485":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3c9993db029a4a9485b0898cd54c40a3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"be14d46a73c94a53a90c754f124723be":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2f6e014f45f144e0b0919a6109af6ec5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0b41609b2dee43d8b0b8ff138480784e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fbbbfc69fe9943c4be0c6ffbcfbb5ec4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ffd8d5bf842b47bf8f1ae875b5740f07","IPY_MODEL_a708c2ca5acd4425ad974e592110a6bf","IPY_MODEL_c5d7aa713137417e892994203e5bdc4a"],"layout":"IPY_MODEL_15f06eb4eaeb4fddb8d7536b6c3a433f"}},"ffd8d5bf842b47bf8f1ae875b5740f07":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_79b9a780f3c841368671abddce9717c5","placeholder":"​","style":"IPY_MODEL_667a44f5d8a3434994fc829ba62603c2","value":"model.safetensors.index.json: 100%"}},"a708c2ca5acd4425ad974e592110a6bf":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_157f81bd7d4f44bdbf82f2b627520bbb","max":26788,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ff6d016f3894a9189bf053cd9a1c49e","value":26788}},"c5d7aa713137417e892994203e5bdc4a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e00f2c685c254b13bcbceefbea95f629","placeholder":"​","style":"IPY_MODEL_d4f01ee237a142c7ab3e2e00975e4eed","value":" 26.8k/26.8k [00:00&lt;00:00, 1.44MB/s]"}},"15f06eb4eaeb4fddb8d7536b6c3a433f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"79b9a780f3c841368671abddce9717c5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"667a44f5d8a3434994fc829ba62603c2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"157f81bd7d4f44bdbf82f2b627520bbb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ff6d016f3894a9189bf053cd9a1c49e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e00f2c685c254b13bcbceefbea95f629":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d4f01ee237a142c7ab3e2e00975e4eed":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5b4cedd865a9487b801ed71ae974df2d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2f93b46c76584174a945a599b15c80ff","IPY_MODEL_1f53fda044a04465b56513c6f5e4fe31","IPY_MODEL_61b8f7c487894865a795ee0b6ffc4332"],"layout":"IPY_MODEL_42dd45f88a004176b9220987977f334d"}},"2f93b46c76584174a945a599b15c80ff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0736676d81304d0cbef75c20c9b5436e","placeholder":"​","style":"IPY_MODEL_6119d03a220e49d4ac41058ab2e94e7c","value":"Downloading shards: 100%"}},"1f53fda044a04465b56513c6f5e4fe31":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_25bdc8f89bcb4ca09454102638730aaa","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ff3c9aa64f54333bfe6f67c892daf50","value":2}},"61b8f7c487894865a795ee0b6ffc4332":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c64b19399ff8476bb5f2e53941064d06","placeholder":"​","style":"IPY_MODEL_17cab47ba46f4904b3db4ee1b0ef9d41","value":" 2/2 [01:54&lt;00:00, 52.08s/it]"}},"42dd45f88a004176b9220987977f334d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0736676d81304d0cbef75c20c9b5436e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6119d03a220e49d4ac41058ab2e94e7c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"25bdc8f89bcb4ca09454102638730aaa":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ff3c9aa64f54333bfe6f67c892daf50":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c64b19399ff8476bb5f2e53941064d06":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"17cab47ba46f4904b3db4ee1b0ef9d41":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"43f8b3e409b143138fed224642561b40":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_fbd4bbe3580d47abaddca88aa3a6e126","IPY_MODEL_ab503bad4edf47fc9d61b01a27e57de8","IPY_MODEL_24b1532703014e2ea2752ca8cf6e2c31"],"layout":"IPY_MODEL_a0a8aea5ad784d5e9fccaaa2c997b626"}},"fbd4bbe3580d47abaddca88aa3a6e126":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a69982cd81643d0a0afa567d179045f","placeholder":"​","style":"IPY_MODEL_4cb13bfc33b84ac3aa15baae58467150","value":"model-00001-of-00002.safetensors: 100%"}},"ab503bad4edf47fc9d61b01a27e57de8":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e5172af9ec724d73b3c2e2c8df54eadb","max":9976576152,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23506f899b144f8989ef58ed9c55522d","value":9976576152}},"24b1532703014e2ea2752ca8cf6e2c31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c10a705b73f8446892cd8bf9a91ef200","placeholder":"​","style":"IPY_MODEL_c8d2aec6ef7f409596d5d83698de8bc7","value":" 9.98G/9.98G [01:27&lt;00:00, 177MB/s]"}},"a0a8aea5ad784d5e9fccaaa2c997b626":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a69982cd81643d0a0afa567d179045f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4cb13bfc33b84ac3aa15baae58467150":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e5172af9ec724d73b3c2e2c8df54eadb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"23506f899b144f8989ef58ed9c55522d":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c10a705b73f8446892cd8bf9a91ef200":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8d2aec6ef7f409596d5d83698de8bc7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7951cea506af4d72bf2768a480c6bb9c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_428d5b18226a49ea920553e8dca96beb","IPY_MODEL_6d6ae38f4d07494ebcbe9290add3671d","IPY_MODEL_9413c9907b2b42b38935b8c74f02ef3e"],"layout":"IPY_MODEL_8afc8a921a694d4d92f55c4c6a03bc16"}},"428d5b18226a49ea920553e8dca96beb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5eee661b37024064bd0a9e8e66b0a5d9","placeholder":"​","style":"IPY_MODEL_aee828f77a5a4eda84e66117e5c7b9ef","value":"model-00002-of-00002.safetensors: 100%"}},"6d6ae38f4d07494ebcbe9290add3671d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_65b02d39b752433fb2e721c7f3b34953","max":3500296424,"min":0,"orientation":"horizontal","style":"IPY_MODEL_348180d650d144cc93c017dc21eadaed","value":3500296424}},"9413c9907b2b42b38935b8c74f02ef3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e670bcd032884f05ab784d04a4c5129b","placeholder":"​","style":"IPY_MODEL_171bbfc7e88f435396ba9f9712f39cbe","value":" 3.50G/3.50G [00:27&lt;00:00, 217MB/s]"}},"8afc8a921a694d4d92f55c4c6a03bc16":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5eee661b37024064bd0a9e8e66b0a5d9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"aee828f77a5a4eda84e66117e5c7b9ef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"65b02d39b752433fb2e721c7f3b34953":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"348180d650d144cc93c017dc21eadaed":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"e670bcd032884f05ab784d04a4c5129b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"171bbfc7e88f435396ba9f9712f39cbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"77e1b9753b8644949a4e90253eed808f":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4f67d7bc1a6f47e7956258ebd8200b1f","IPY_MODEL_fb77edfc332846c59cc39137deeca108","IPY_MODEL_217974c37ab243ada1ae2583a7f4701b"],"layout":"IPY_MODEL_f6262fd95d07483fb040c858761bb5d3"}},"4f67d7bc1a6f47e7956258ebd8200b1f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c3ac464b1d84892a36744eab356f15e","placeholder":"​","style":"IPY_MODEL_fea18c42b25e43e3b6eadd9c080d6b9e","value":"Loading checkpoint shards: 100%"}},"fb77edfc332846c59cc39137deeca108":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4762d154c4a440028572c0372371b15b","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f286dca171e84c7f9ed0338037003943","value":2}},"217974c37ab243ada1ae2583a7f4701b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_67903a0036f243d381123b73a4a9dc46","placeholder":"​","style":"IPY_MODEL_312af57bab6c432b9be5f1d34e9c9618","value":" 2/2 [00:55&lt;00:00, 25.25s/it]"}},"f6262fd95d07483fb040c858761bb5d3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9c3ac464b1d84892a36744eab356f15e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fea18c42b25e43e3b6eadd9c080d6b9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4762d154c4a440028572c0372371b15b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f286dca171e84c7f9ed0338037003943":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"67903a0036f243d381123b73a4a9dc46":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"312af57bab6c432b9be5f1d34e9c9618":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5c57357d9a65485eb18d7738f1e8d49e":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_b3c15d64a2684bd3b364206efeaf1a12","IPY_MODEL_2acd623272444141a58e738149e559bc","IPY_MODEL_f85fd27aed5a4d9983fd43893f449c79"],"layout":"IPY_MODEL_673529b7928e47faa854f691897ca057"}},"b3c15d64a2684bd3b364206efeaf1a12":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e2748f1699be4f128fd8079bb7ef2e59","placeholder":"​","style":"IPY_MODEL_779cec7a2bba4abf929f82b879ffd011","value":"generation_config.json: 100%"}},"2acd623272444141a58e738149e559bc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f4131eb29d81442081ff283803ca13e8","max":188,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4c9fab1ef38044aea6bf2422d888a7b1","value":188}},"f85fd27aed5a4d9983fd43893f449c79":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d5506cd4e3ae473abba6a28f52195591","placeholder":"​","style":"IPY_MODEL_f1aa05222c97452fb433baa9ee7b6306","value":" 188/188 [00:00&lt;00:00, 13.2kB/s]"}},"673529b7928e47faa854f691897ca057":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2748f1699be4f128fd8079bb7ef2e59":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"779cec7a2bba4abf929f82b879ffd011":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f4131eb29d81442081ff283803ca13e8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4c9fab1ef38044aea6bf2422d888a7b1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d5506cd4e3ae473abba6a28f52195591":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f1aa05222c97452fb433baa9ee7b6306":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"92c6a95d26bc4856b50124c00c217d81":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f440961022cc4b128a54f07ca6724a5b","IPY_MODEL_284cb6500b51466f81dc9545592343f0","IPY_MODEL_550066fc6dcf4e538185b40ff638bd3e"],"layout":"IPY_MODEL_cbe5602eb5de4348adfa59cec26adbbf"}},"f440961022cc4b128a54f07ca6724a5b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_0509d90301c44e6aae6a4fc2e3df737e","placeholder":"​","style":"IPY_MODEL_1168de90f8614b9f896e4b8ce813a6f0","value":"adapter_config.json: 100%"}},"284cb6500b51466f81dc9545592343f0":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a56e22403cfe4c5e99b2ae95faa5cf37","max":620,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5ba312ed875c4158957b5a796d629cc4","value":620}},"550066fc6dcf4e538185b40ff638bd3e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1d6291fa5a8f4e599f653236700a151f","placeholder":"​","style":"IPY_MODEL_813caa8a28f34534bbd48681237eeeb8","value":" 620/620 [00:00&lt;00:00, 41.2kB/s]"}},"cbe5602eb5de4348adfa59cec26adbbf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0509d90301c44e6aae6a4fc2e3df737e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1168de90f8614b9f896e4b8ce813a6f0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a56e22403cfe4c5e99b2ae95faa5cf37":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ba312ed875c4158957b5a796d629cc4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1d6291fa5a8f4e599f653236700a151f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"813caa8a28f34534bbd48681237eeeb8":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2b2e89b395ae4d268145af8bcb5ec15c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30ba8ff9a0ea4e15839858f9b8c4e589","IPY_MODEL_a4c86b402e0244ee9addd01005a99f16","IPY_MODEL_bf06121d40084203abc52f34e19b3445"],"layout":"IPY_MODEL_8d253e9f6b0c4113a20a6b8b24974994"}},"30ba8ff9a0ea4e15839858f9b8c4e589":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6381541b1df64cb5a7aa2d066d051fd3","placeholder":"​","style":"IPY_MODEL_a0f93b2ba6ff49d4a860e296bc6efb6e","value":"adapter_model.safetensors: 100%"}},"a4c86b402e0244ee9addd01005a99f16":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_542f95945a0f4c53a11cabc8aaff6da1","max":16794200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_69dd068e9d6a420bab7d1e58d3020281","value":16794200}},"bf06121d40084203abc52f34e19b3445":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_faac687f757f4395badcb31aacc62002","placeholder":"​","style":"IPY_MODEL_7eeab530c08546248b7841a916922dc5","value":" 16.8M/16.8M [00:00&lt;00:00, 97.4MB/s]"}},"8d253e9f6b0c4113a20a6b8b24974994":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6381541b1df64cb5a7aa2d066d051fd3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0f93b2ba6ff49d4a860e296bc6efb6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"542f95945a0f4c53a11cabc8aaff6da1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"69dd068e9d6a420bab7d1e58d3020281":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"faac687f757f4395badcb31aacc62002":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7eeab530c08546248b7841a916922dc5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7f64cb92066a44018abba1eb06e35678":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5b69b6ca28d14961a5b9363bb6632526","IPY_MODEL_010dd2b744894363b971a8ae5ed3fb64","IPY_MODEL_f70565bd01e843e89668b6e510de0072"],"layout":"IPY_MODEL_361d8b1687b8427fb445b6334a973b7d"}},"5b69b6ca28d14961a5b9363bb6632526":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6cffddb870a9425686f7a8e28d06727e","placeholder":"​","style":"IPY_MODEL_9122c1576dbb45d1bcf7f64ac63a8f97","value":"tokenizer_config.json: 100%"}},"010dd2b744894363b971a8ae5ed3fb64":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d299f7a9770545f18574916f20710af5","max":1618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cecd9ffe89b6400592a885af094be3a6","value":1618}},"f70565bd01e843e89668b6e510de0072":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_3b77347145a9448aad207b30f594a47f","placeholder":"​","style":"IPY_MODEL_2b4bdd42f9364c679f3e029624b4ae0c","value":" 1.62k/1.62k [00:00&lt;00:00, 117kB/s]"}},"361d8b1687b8427fb445b6334a973b7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6cffddb870a9425686f7a8e28d06727e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9122c1576dbb45d1bcf7f64ac63a8f97":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d299f7a9770545f18574916f20710af5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cecd9ffe89b6400592a885af094be3a6":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"3b77347145a9448aad207b30f594a47f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2b4bdd42f9364c679f3e029624b4ae0c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"72be2251177e4461bb9c5961b2c7d2ab":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1de214320e174ca2baeb1f5512b8f627","IPY_MODEL_d1295a52a2bc4b32813236d809039d8f","IPY_MODEL_bb96015d2ba04039a9c3d5a59308b235"],"layout":"IPY_MODEL_c7252fbcda1e4a12b66cc90954e9f8eb"}},"1de214320e174ca2baeb1f5512b8f627":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_78626096310f493dae7805cb7f0b185f","placeholder":"​","style":"IPY_MODEL_88e86657e852460aa0a37af61c5e2391","value":"tokenizer.model: 100%"}},"d1295a52a2bc4b32813236d809039d8f":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4a7d00c826d842a39704edcb0cabe0b5","max":499723,"min":0,"orientation":"horizontal","style":"IPY_MODEL_8ebb81ad59024169aca05efec706b1cd","value":499723}},"bb96015d2ba04039a9c3d5a59308b235":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2a0dea39869043c8bc7e2c434397ba0d","placeholder":"​","style":"IPY_MODEL_fc2563594db34169a6750e3ee6039763","value":" 500k/500k [00:00&lt;00:00, 28.2MB/s]"}},"c7252fbcda1e4a12b66cc90954e9f8eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"78626096310f493dae7805cb7f0b185f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"88e86657e852460aa0a37af61c5e2391":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4a7d00c826d842a39704edcb0cabe0b5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ebb81ad59024169aca05efec706b1cd":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2a0dea39869043c8bc7e2c434397ba0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc2563594db34169a6750e3ee6039763":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"29047e5b812241c39239b228f7a7ee8b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ab5710fdef6c42658cd2e33122878b14","IPY_MODEL_76ada1d38e494c29a0398c9e7c681b97","IPY_MODEL_339211715e1d483686b6b5a8ff926d81"],"layout":"IPY_MODEL_55871e0ff8864638b58efd8617618228"}},"ab5710fdef6c42658cd2e33122878b14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2ddaed580594359b7e8193d2080a0bb","placeholder":"​","style":"IPY_MODEL_e028e7824ead4623818cfb47c5e4c6fd","value":"tokenizer.json: 100%"}},"76ada1d38e494c29a0398c9e7c681b97":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cb9e75a747294f8fa0547a17bea1a9a2","max":1842767,"min":0,"orientation":"horizontal","style":"IPY_MODEL_f7bc01d110bf44d8a52e6665b3432de8","value":1842767}},"339211715e1d483686b6b5a8ff926d81":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c76ce9ea4ee4412ba3270def35732a53","placeholder":"​","style":"IPY_MODEL_df2b81a24a454febb12e218f9a5c5039","value":" 1.84M/1.84M [00:00&lt;00:00, 5.62MB/s]"}},"55871e0ff8864638b58efd8617618228":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2ddaed580594359b7e8193d2080a0bb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e028e7824ead4623818cfb47c5e4c6fd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cb9e75a747294f8fa0547a17bea1a9a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f7bc01d110bf44d8a52e6665b3432de8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c76ce9ea4ee4412ba3270def35732a53":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"df2b81a24a454febb12e218f9a5c5039":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ee85ad10f99f425ab006d52c9dd28da4":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_30585fbdb139407fa2021b86db07ab52","IPY_MODEL_eeb9b2b2aaf94f12a13180540304827d","IPY_MODEL_c5862c278d534464a9b88fcea9e88e3c"],"layout":"IPY_MODEL_d3ddaf7b87cd4414a679585f4be1064d"}},"30585fbdb139407fa2021b86db07ab52":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c2032c7a7c0449c489e7dacbde7b1aa4","placeholder":"​","style":"IPY_MODEL_f82f4241a0d24d79b34fee7532db6d2d","value":"special_tokens_map.json: 100%"}},"eeb9b2b2aaf94f12a13180540304827d":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4fa57e487d67480d8971fdf92722ed96","max":414,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2ba57322791e45cc9df894fc89738709","value":414}},"c5862c278d534464a9b88fcea9e88e3c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_dae953ab7f284d23b2173daf2d0a7f9b","placeholder":"​","style":"IPY_MODEL_75d4a2a6a0ba46d79db52f4266a2424d","value":" 414/414 [00:00&lt;00:00, 29.3kB/s]"}},"d3ddaf7b87cd4414a679585f4be1064d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c2032c7a7c0449c489e7dacbde7b1aa4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f82f4241a0d24d79b34fee7532db6d2d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4fa57e487d67480d8971fdf92722ed96":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2ba57322791e45cc9df894fc89738709":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"dae953ab7f284d23b2173daf2d0a7f9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75d4a2a6a0ba46d79db52f4266a2424d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"338ca630e387453d8bf2b12247a43677":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0a9754786c13466ab6e7bcadc7eed5b5","IPY_MODEL_0cabdc2ebbee49e19f0677a483e5e736","IPY_MODEL_de227e0cd5c1469a8e038e2a4ccddf7f"],"layout":"IPY_MODEL_cd17c551e4384f63980eebec23f18190"}},"0a9754786c13466ab6e7bcadc7eed5b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b415d4f8a08744498d5882e112a14e2a","placeholder":"​","style":"IPY_MODEL_16273bb0e9b048de80a63ed9ef32cf7a","value":"model-00001-of-00003.safetensors: 100%"}},"0cabdc2ebbee49e19f0677a483e5e736":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c0c76d248fc646e1aac79adab29e68d7","max":4938985248,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2bfbbe704f5402b9ddcd934881ffefa","value":4938985248}},"de227e0cd5c1469a8e038e2a4ccddf7f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ef7903cf7a0481fa6bc30efc62930f1","placeholder":"​","style":"IPY_MODEL_40dc3d9801bd45abbe5dc173402fb393","value":" 4.94G/4.94G [02:34&lt;00:00, 37.2MB/s]"}},"cd17c551e4384f63980eebec23f18190":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b415d4f8a08744498d5882e112a14e2a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"16273bb0e9b048de80a63ed9ef32cf7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c0c76d248fc646e1aac79adab29e68d7":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2bfbbe704f5402b9ddcd934881ffefa":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ef7903cf7a0481fa6bc30efc62930f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40dc3d9801bd45abbe5dc173402fb393":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"786e4720858a444a996f3f9891b9b0c1":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_1854263372374fbb973c0b446744e3b8","IPY_MODEL_8850bac428ff4480919526a0c1fd7db1","IPY_MODEL_243992f5abb5427eb1ddb88169ca251c"],"layout":"IPY_MODEL_938162276df94cb9be42ff1ae50f2439"}},"1854263372374fbb973c0b446744e3b8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_45e3e514d48d4a4c9c6ee6218d0fcb6c","placeholder":"​","style":"IPY_MODEL_41094c1478554dc8aabe0f1e433f2785","value":"model-00002-of-00003.safetensors: 100%"}},"8850bac428ff4480919526a0c1fd7db1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1359ec5804634b1ab1d90892d68e00a8","max":4947390768,"min":0,"orientation":"horizontal","style":"IPY_MODEL_75629309b7344aee99230a320af2bd3f","value":4947390768}},"243992f5abb5427eb1ddb88169ca251c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4b5235ba89ca4245b924e0041ac5bc5f","placeholder":"​","style":"IPY_MODEL_4a1f3b50bdf84b3392eecf6744d86221","value":" 4.95G/4.95G [02:35&lt;00:00, 49.9MB/s]"}},"938162276df94cb9be42ff1ae50f2439":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"45e3e514d48d4a4c9c6ee6218d0fcb6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"41094c1478554dc8aabe0f1e433f2785":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1359ec5804634b1ab1d90892d68e00a8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75629309b7344aee99230a320af2bd3f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"4b5235ba89ca4245b924e0041ac5bc5f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4a1f3b50bdf84b3392eecf6744d86221":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f91d7cbe64ad423596b70137d23f0275":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4ed9df28aa6049ff93f234900a61bbb7","IPY_MODEL_9ea165165a104fefae7f6ace1ee616eb","IPY_MODEL_f56d4d9fe13b4d2e8a8a67ac2e1fc01d"],"layout":"IPY_MODEL_1960887f25d84d07b088fd186456780f"}},"4ed9df28aa6049ff93f234900a61bbb7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bddda3d36f634eefa3d2856d533fb12d","placeholder":"​","style":"IPY_MODEL_8934ba939caa41c99dbe02ff5cb256a5","value":"Upload 3 LFS files: 100%"}},"9ea165165a104fefae7f6ace1ee616eb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_e14bd3b0528149b78fcef6a4cdcc89fb","max":3,"min":0,"orientation":"horizontal","style":"IPY_MODEL_de8da966211443be94725074fa20f71b","value":3}},"f56d4d9fe13b4d2e8a8a67ac2e1fc01d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_33b203bf82664442ac519334c8895dcb","placeholder":"​","style":"IPY_MODEL_a18ee82cc1de42758431c2e549cdfb8e","value":" 3/3 [02:35&lt;00:00, 64.36s/it]"}},"1960887f25d84d07b088fd186456780f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bddda3d36f634eefa3d2856d533fb12d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8934ba939caa41c99dbe02ff5cb256a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e14bd3b0528149b78fcef6a4cdcc89fb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"de8da966211443be94725074fa20f71b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"33b203bf82664442ac519334c8895dcb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a18ee82cc1de42758431c2e549cdfb8e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"e95c94c3604f47ec825de1fe80e04871":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3a398b45a3a841908146f801fcb66e5f","IPY_MODEL_13f7a3ea34ad458eab64abd7c5ca50a3","IPY_MODEL_1ad3cfcc22eb4d4098ad21abc31fed83"],"layout":"IPY_MODEL_a11485ac628943cba051801777d1877b"}},"3a398b45a3a841908146f801fcb66e5f":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_bfba43846a8141a08da931d96c5c6529","placeholder":"​","style":"IPY_MODEL_0d32547a760848b295f039849933093c","value":"model-00003-of-00003.safetensors: 100%"}},"13f7a3ea34ad458eab64abd7c5ca50a3":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c2fce34a4df466baf510b7413825913","max":3590488736,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71f38db6792a4a7e917dc78ee13786ca","value":3590488736}},"1ad3cfcc22eb4d4098ad21abc31fed83":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6842fc5adff94725b544ae1ddb0211b1","placeholder":"​","style":"IPY_MODEL_294edcc1ddde487d97242831a7b159f6","value":" 3.59G/3.59G [01:53&lt;00:00, 20.2MB/s]"}},"a11485ac628943cba051801777d1877b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bfba43846a8141a08da931d96c5c6529":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0d32547a760848b295f039849933093c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c2fce34a4df466baf510b7413825913":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71f38db6792a4a7e917dc78ee13786ca":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6842fc5adff94725b544ae1ddb0211b1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"294edcc1ddde487d97242831a7b159f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8141f60a027495d9dca6b1891726832":{"model_module":"@jupyter-widgets/controls","model_name":"VBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"VBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"VBoxView","box_style":"","children":["IPY_MODEL_a602512e878c4dc29bb6cf2d54f6d385","IPY_MODEL_2a43a44ff1c44b9d8987606a8d453027","IPY_MODEL_aa8797ddf70447f791fd1a9ab10ee834","IPY_MODEL_0d7ff6c27b2049ec980b6c0730afb735"],"layout":"IPY_MODEL_798e3f26e0d14bff94f2c5240ede4ac1"}},"60168be8ba854d299e1d7a73a0904f08":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_88a88a2c4a55414aafa1b536cb62479d","placeholder":"​","style":"IPY_MODEL_5ee89c6d1f1247f0a56763496032b4d1","value":"<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"}},"08dc8d15fe624335b756a864a856e151":{"model_module":"@jupyter-widgets/controls","model_name":"PasswordModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"PasswordModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"PasswordView","continuous_update":true,"description":"Token:","description_tooltip":null,"disabled":false,"layout":"IPY_MODEL_a5e3724a95f34dff988fd2ba3381ffb3","placeholder":"​","style":"IPY_MODEL_cad476cc27ea4f05800f2b51e2b2816f","value":""}},"ee00a02258e2464785cad6122b324ace":{"model_module":"@jupyter-widgets/controls","model_name":"CheckboxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"CheckboxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"CheckboxView","description":"Add token as git credential?","description_tooltip":null,"disabled":false,"indent":true,"layout":"IPY_MODEL_ab5a64e958f048bc91f29dc96f82a10e","style":"IPY_MODEL_b5091fcdd5df4aa491a9775836f69a50","value":true}},"d4f5b2ac123c4ca08be9a94ffad53b29":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ButtonView","button_style":"","description":"Login","disabled":false,"icon":"","layout":"IPY_MODEL_3f94cec911184cb1abd87ffc3c68f898","style":"IPY_MODEL_4b0e6e7ed95f4a4c81aaf45153ad0c38","tooltip":""}},"8e799d2aadab4c20a5e5752162bf5ee5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7e926a5e61444777b31c941e8722e112","placeholder":"​","style":"IPY_MODEL_d8d91753de43484fa9ff40e71377c6bb","value":"\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"}},"798e3f26e0d14bff94f2c5240ede4ac1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":"center","align_self":null,"border":null,"bottom":null,"display":"flex","flex":null,"flex_flow":"column","grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"50%"}},"88a88a2c4a55414aafa1b536cb62479d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ee89c6d1f1247f0a56763496032b4d1":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a5e3724a95f34dff988fd2ba3381ffb3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cad476cc27ea4f05800f2b51e2b2816f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ab5a64e958f048bc91f29dc96f82a10e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b5091fcdd5df4aa491a9775836f69a50":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"3f94cec911184cb1abd87ffc3c68f898":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b0e6e7ed95f4a4c81aaf45153ad0c38":{"model_module":"@jupyter-widgets/controls","model_name":"ButtonStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ButtonStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","button_color":null,"font_weight":""}},"7e926a5e61444777b31c941e8722e112":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d8d91753de43484fa9ff40e71377c6bb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d5cac79a28a142deb898fba5e778cbbb":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_141c8420cd334c7aacfead039e2550c3","placeholder":"​","style":"IPY_MODEL_d93b6d6aa2d9429283b0bbab1a10720a","value":"Connecting..."}},"141c8420cd334c7aacfead039e2550c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d93b6d6aa2d9429283b0bbab1a10720a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a602512e878c4dc29bb6cf2d54f6d385":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_04353fe66ef6468495a22d542526c4e6","placeholder":"​","style":"IPY_MODEL_db3a6c25c4da49b59f93f9fbe483fafd","value":"Token is valid (permission: write)."}},"2a43a44ff1c44b9d8987606a8d453027":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c8c030dc028e46689e14f3c194635612","placeholder":"​","style":"IPY_MODEL_f9a5dfcf6a0e4848a0143c023bef1e8a","value":"Your token has been saved in your configured git credential helpers (store)."}},"aa8797ddf70447f791fd1a9ab10ee834":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_386b6d6d906b4bee96628e11c2f3b181","placeholder":"​","style":"IPY_MODEL_eb5a3de45b31415c8c75396b0148dd3b","value":"Your token has been saved to /root/.cache/huggingface/token"}},"0d7ff6c27b2049ec980b6c0730afb735":{"model_module":"@jupyter-widgets/controls","model_name":"LabelModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"LabelModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"LabelView","description":"","description_tooltip":null,"layout":"IPY_MODEL_20171f924a374721a633313cf619d5d1","placeholder":"​","style":"IPY_MODEL_8581e93dd4cd41a995deb122b3abebd4","value":"Login successful"}},"04353fe66ef6468495a22d542526c4e6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"db3a6c25c4da49b59f93f9fbe483fafd":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c8c030dc028e46689e14f3c194635612":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f9a5dfcf6a0e4848a0143c023bef1e8a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"386b6d6d906b4bee96628e11c2f3b181":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eb5a3de45b31415c8c75396b0148dd3b":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"20171f924a374721a633313cf619d5d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8581e93dd4cd41a995deb122b3abebd4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6ee6ee2a6bef45db82f4350799bbb2e0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bc3116b8bf3d407f93438bb826ec1b59","IPY_MODEL_201ba60d566f49b9975522e57c564c22","IPY_MODEL_6a869e085224498082c136920b2bcfcc"],"layout":"IPY_MODEL_565aa8a47a2a4626b75121b9203f3cf3"}},"bc3116b8bf3d407f93438bb826ec1b59":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5f3053bb1ae74b70970c8246f7ff2d79","placeholder":"​","style":"IPY_MODEL_a4d1994c20874f4cb7cb18d7b3515544","value":"code-llama2-Q4_K_M.gguf: 100%"}},"201ba60d566f49b9975522e57c564c22":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_c488be7fc1b3475cb97859b49b39e21d","max":4081005184,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2f253a0de7ea4715ac69eb35c458e45f","value":4081005184}},"6a869e085224498082c136920b2bcfcc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fd6c024292647329aacd440d4e5d432","placeholder":"​","style":"IPY_MODEL_a061cecabe064444b04a4c94dab75953","value":" 4.08G/4.08G [01:57&lt;00:00, 48.2MB/s]"}},"565aa8a47a2a4626b75121b9203f3cf3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5f3053bb1ae74b70970c8246f7ff2d79":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a4d1994c20874f4cb7cb18d7b3515544":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c488be7fc1b3475cb97859b49b39e21d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2f253a0de7ea4715ac69eb35c458e45f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8fd6c024292647329aacd440d4e5d432":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a061cecabe064444b04a4c94dab75953":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1GrY2Bgqi5tsPgAoxJ2eF8Z_JRpUADN89#scrollTo=kAkdN0jZpgDF)"],"metadata":{"id":"x8vujvp9qLeJ"}},{"cell_type":"markdown","source":["# First load adapter and base model to merge them togther then save it to convert it to bf16 and quatize to 4 and 5 bit gguf"],"metadata":{"id":"kAkdN0jZpgDF"}},{"cell_type":"code","source":["!pip install -q transformers peft"],"metadata":{"trusted":true,"id":"IJpHa5mBbonU","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709597012772,"user_tz":-120,"elapsed":8582,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"8d74f757-e1aa-4fbb-ef5e-4cfc8b931b0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}]},{"cell_type":"code","source":["import os\n","import shutil\n","import torch\n","import warnings\n","\n","from transformers import AutoModelForCausalLM, AutoTokenizer\n","from peft import PeftModel"],"metadata":{"trusted":true,"id":"YBuFYvWZbonV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["warnings.filterwarnings( \"ignore\" )\n","\n","baseModel = \"meta-llama/Llama-2-7b-chat-hf\"\n","peft      = \"Elkhayyat17/qlora-code-llama2\"\n","outdir    = \"/content/merged\""],"metadata":{"trusted":true,"id":"9Ic0sXJ5bonV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from huggingface_hub import login\n","login()"],"metadata":{"trusted":true,"id":"0z-Z4CwZbonW","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["342da0cbc8f14b2ba99b3d2f6e2e91d4","497fa99e4f744730aa6e151884381d5e","b962fd5b51e84295b511a63320a4b0b8","f811072481ad41a5b52817a0291df1a1","253b3dee1cb9456dbcf91c1daf6a0dc4","45fbc916594e4daab09421fe5d95e416","865e8ce5389443e8b9dfc75dec621cad","bd3fe2decfa049239396fc826d54269d","f9e31cd9cdad40ea87b2093a2c608336","222b2df734774c78b77de46e6d647cb7","91dc76fdd5c74b1fa03b8aabd08af1a3","a4210d8155b64656a3c84f3908568255","f31d73ef9147439a84034e55089440e1","8ffe303e94eb4af5b18891522d2e8a43","01061c93a0604988b13a1115c45d3b51","f911253d429047399677f11c639aefc1","31913fca0bef4e32a632134a0aeb2512","8c01db764e6a4291b6cd6592fbebb706","e779786c10b843ea862600781db64313","9172bbd39a4c4ff4aa794a6e5818d21a","f4539c1a9d284ea79b714291f518f85e","a4db71875cc3421599ca0ddfc61790ee","ff29927c978d4d868e45aaf6f94d03e6","c8250a4ff49743089c4386a60a948d36","03d8e9eb958b4ddca60fd735ae464c9d","f1c9c23874804669850d29c94504c635","c82effc3a4894083acf579b311262d2d","5185ec2adb884c18b58d9688bb7b24e4","5964496e744e44b0a88ed54f51b81b13","5df792c9f7d04277a4c4eac84111939a","45042afffd8d48c79c2bb58db476bfbd","a0de1924ea1f410aae857b5fe59c9822"]},"executionInfo":{"status":"ok","timestamp":1709597025426,"user_tz":-120,"elapsed":8,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"16b6dc66-172f-4a07-ce29-802449e3926a"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"342da0cbc8f14b2ba99b3d2f6e2e91d4"}},"metadata":{}}]},{"cell_type":"code","source":["print( f\"Loading base model: {baseModel}\")\n","model = AutoModelForCausalLM.from_pretrained(\n","    baseModel,\n","    torch_dtype = torch.float16,\n","    device_map = \"cuda\"\n",")"],"metadata":{"trusted":true,"id":"rfwkTdK_bonW","colab":{"base_uri":"https://localhost:8080/","height":258,"referenced_widgets":["465bf7c1f6c0423eaf1f8138354433b3","f48928ade2244c95b7f5cb4a445a7237","17103cef13034b23a38859f62df8fab5","18240277f2e9473aa5290aff38110a56","e9e9bd528bfe485bb228abe7dd2f4e37","2ab110a027254342bef333f6dd437c8c","5d5823055dff474d85003d25e8bd1485","3c9993db029a4a9485b0898cd54c40a3","be14d46a73c94a53a90c754f124723be","2f6e014f45f144e0b0919a6109af6ec5","0b41609b2dee43d8b0b8ff138480784e","fbbbfc69fe9943c4be0c6ffbcfbb5ec4","ffd8d5bf842b47bf8f1ae875b5740f07","a708c2ca5acd4425ad974e592110a6bf","c5d7aa713137417e892994203e5bdc4a","15f06eb4eaeb4fddb8d7536b6c3a433f","79b9a780f3c841368671abddce9717c5","667a44f5d8a3434994fc829ba62603c2","157f81bd7d4f44bdbf82f2b627520bbb","8ff6d016f3894a9189bf053cd9a1c49e","e00f2c685c254b13bcbceefbea95f629","d4f01ee237a142c7ab3e2e00975e4eed","5b4cedd865a9487b801ed71ae974df2d","2f93b46c76584174a945a599b15c80ff","1f53fda044a04465b56513c6f5e4fe31","61b8f7c487894865a795ee0b6ffc4332","42dd45f88a004176b9220987977f334d","0736676d81304d0cbef75c20c9b5436e","6119d03a220e49d4ac41058ab2e94e7c","25bdc8f89bcb4ca09454102638730aaa","5ff3c9aa64f54333bfe6f67c892daf50","c64b19399ff8476bb5f2e53941064d06","17cab47ba46f4904b3db4ee1b0ef9d41","43f8b3e409b143138fed224642561b40","fbd4bbe3580d47abaddca88aa3a6e126","ab503bad4edf47fc9d61b01a27e57de8","24b1532703014e2ea2752ca8cf6e2c31","a0a8aea5ad784d5e9fccaaa2c997b626","4a69982cd81643d0a0afa567d179045f","4cb13bfc33b84ac3aa15baae58467150","e5172af9ec724d73b3c2e2c8df54eadb","23506f899b144f8989ef58ed9c55522d","c10a705b73f8446892cd8bf9a91ef200","c8d2aec6ef7f409596d5d83698de8bc7","7951cea506af4d72bf2768a480c6bb9c","428d5b18226a49ea920553e8dca96beb","6d6ae38f4d07494ebcbe9290add3671d","9413c9907b2b42b38935b8c74f02ef3e","8afc8a921a694d4d92f55c4c6a03bc16","5eee661b37024064bd0a9e8e66b0a5d9","aee828f77a5a4eda84e66117e5c7b9ef","65b02d39b752433fb2e721c7f3b34953","348180d650d144cc93c017dc21eadaed","e670bcd032884f05ab784d04a4c5129b","171bbfc7e88f435396ba9f9712f39cbe","77e1b9753b8644949a4e90253eed808f","4f67d7bc1a6f47e7956258ebd8200b1f","fb77edfc332846c59cc39137deeca108","217974c37ab243ada1ae2583a7f4701b","f6262fd95d07483fb040c858761bb5d3","9c3ac464b1d84892a36744eab356f15e","fea18c42b25e43e3b6eadd9c080d6b9e","4762d154c4a440028572c0372371b15b","f286dca171e84c7f9ed0338037003943","67903a0036f243d381123b73a4a9dc46","312af57bab6c432b9be5f1d34e9c9618","5c57357d9a65485eb18d7738f1e8d49e","b3c15d64a2684bd3b364206efeaf1a12","2acd623272444141a58e738149e559bc","f85fd27aed5a4d9983fd43893f449c79","673529b7928e47faa854f691897ca057","e2748f1699be4f128fd8079bb7ef2e59","779cec7a2bba4abf929f82b879ffd011","f4131eb29d81442081ff283803ca13e8","4c9fab1ef38044aea6bf2422d888a7b1","d5506cd4e3ae473abba6a28f52195591","f1aa05222c97452fb433baa9ee7b6306"]},"executionInfo":{"status":"ok","timestamp":1709597226485,"user_tz":-120,"elapsed":174535,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"60edc60f-e309-4895-ece5-ce42a9f8dbd4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading base model: meta-llama/Llama-2-7b-chat-hf\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"465bf7c1f6c0423eaf1f8138354433b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fbbbfc69fe9943c4be0c6ffbcfbb5ec4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b4cedd865a9487b801ed71ae974df2d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"43f8b3e409b143138fed224642561b40"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7951cea506af4d72bf2768a480c6bb9c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"77e1b9753b8644949a4e90253eed808f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c57357d9a65485eb18d7738f1e8d49e"}},"metadata":{}}]},{"cell_type":"code","source":["print( f\"Loading PEFT: {peft}\" )\n","model = PeftModel.from_pretrained( model, peft )\n","print( \"Running merge_and_unload\" )\n","model = model.merge_and_unload()"],"metadata":{"trusted":true,"id":"eag-oEonbonX","colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["92c6a95d26bc4856b50124c00c217d81","f440961022cc4b128a54f07ca6724a5b","284cb6500b51466f81dc9545592343f0","550066fc6dcf4e538185b40ff638bd3e","cbe5602eb5de4348adfa59cec26adbbf","0509d90301c44e6aae6a4fc2e3df737e","1168de90f8614b9f896e4b8ce813a6f0","a56e22403cfe4c5e99b2ae95faa5cf37","5ba312ed875c4158957b5a796d629cc4","1d6291fa5a8f4e599f653236700a151f","813caa8a28f34534bbd48681237eeeb8","2b2e89b395ae4d268145af8bcb5ec15c","30ba8ff9a0ea4e15839858f9b8c4e589","a4c86b402e0244ee9addd01005a99f16","bf06121d40084203abc52f34e19b3445","8d253e9f6b0c4113a20a6b8b24974994","6381541b1df64cb5a7aa2d066d051fd3","a0f93b2ba6ff49d4a860e296bc6efb6e","542f95945a0f4c53a11cabc8aaff6da1","69dd068e9d6a420bab7d1e58d3020281","faac687f757f4395badcb31aacc62002","7eeab530c08546248b7841a916922dc5"]},"executionInfo":{"status":"ok","timestamp":1709597228168,"user_tz":-120,"elapsed":1688,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"96a08f3a-c63d-48c6-a379-cc6d86a0fde5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading PEFT: Elkhayyat17/qlora-code-llama2\n"]},{"output_type":"display_data","data":{"text/plain":["adapter_config.json:   0%|          | 0.00/620 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c6a95d26bc4856b50124c00c217d81"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["adapter_model.safetensors:   0%|          | 0.00/16.8M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b2e89b395ae4d268145af8bcb5ec15c"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Running merge_and_unload\n"]}]},{"cell_type":"code","source":["\n","tokenizer = AutoTokenizer.from_pretrained( baseModel )\n","\n","if os.path.isdir( outdir ):\n","    shutil.rmtree( outdir )\n","\n","model.save_pretrained( outdir )\n","tokenizer.save_pretrained( outdir )\n","print( f\"Model saved to {outdir}\" )"],"metadata":{"trusted":true,"id":"lv_knxHubonX","colab":{"base_uri":"https://localhost:8080/","height":162,"referenced_widgets":["7f64cb92066a44018abba1eb06e35678","5b69b6ca28d14961a5b9363bb6632526","010dd2b744894363b971a8ae5ed3fb64","f70565bd01e843e89668b6e510de0072","361d8b1687b8427fb445b6334a973b7d","6cffddb870a9425686f7a8e28d06727e","9122c1576dbb45d1bcf7f64ac63a8f97","d299f7a9770545f18574916f20710af5","cecd9ffe89b6400592a885af094be3a6","3b77347145a9448aad207b30f594a47f","2b4bdd42f9364c679f3e029624b4ae0c","72be2251177e4461bb9c5961b2c7d2ab","1de214320e174ca2baeb1f5512b8f627","d1295a52a2bc4b32813236d809039d8f","bb96015d2ba04039a9c3d5a59308b235","c7252fbcda1e4a12b66cc90954e9f8eb","78626096310f493dae7805cb7f0b185f","88e86657e852460aa0a37af61c5e2391","4a7d00c826d842a39704edcb0cabe0b5","8ebb81ad59024169aca05efec706b1cd","2a0dea39869043c8bc7e2c434397ba0d","fc2563594db34169a6750e3ee6039763","29047e5b812241c39239b228f7a7ee8b","ab5710fdef6c42658cd2e33122878b14","76ada1d38e494c29a0398c9e7c681b97","339211715e1d483686b6b5a8ff926d81","55871e0ff8864638b58efd8617618228","c2ddaed580594359b7e8193d2080a0bb","e028e7824ead4623818cfb47c5e4c6fd","cb9e75a747294f8fa0547a17bea1a9a2","f7bc01d110bf44d8a52e6665b3432de8","c76ce9ea4ee4412ba3270def35732a53","df2b81a24a454febb12e218f9a5c5039","ee85ad10f99f425ab006d52c9dd28da4","30585fbdb139407fa2021b86db07ab52","eeb9b2b2aaf94f12a13180540304827d","c5862c278d534464a9b88fcea9e88e3c","d3ddaf7b87cd4414a679585f4be1064d","c2032c7a7c0449c489e7dacbde7b1aa4","f82f4241a0d24d79b34fee7532db6d2d","4fa57e487d67480d8971fdf92722ed96","2ba57322791e45cc9df894fc89738709","dae953ab7f284d23b2173daf2d0a7f9b","75d4a2a6a0ba46d79db52f4266a2424d"]},"executionInfo":{"status":"ok","timestamp":1709597372375,"user_tz":-120,"elapsed":144211,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"4bd82b50-eaf4-4167-fbb3-0f5ce6a5fda6"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["tokenizer_config.json:   0%|          | 0.00/1.62k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7f64cb92066a44018abba1eb06e35678"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"72be2251177e4461bb9c5961b2c7d2ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"29047e5b812241c39239b228f7a7ee8b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee85ad10f99f425ab006d52c9dd28da4"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Model saved to /content/merged\n"]}]},{"cell_type":"markdown","source":["##next cell if you want to push merged model to HF"],"metadata":{"id":"Y-JU7xho9l-D"}},{"cell_type":"code","source":["#create repo for merged model\n","model.push_to_hub(repo_id=\"merged-code-llama2\")"],"metadata":{"id":"TCODRQary2Br","colab":{"base_uri":"https://localhost:8080/","height":214,"referenced_widgets":["338ca630e387453d8bf2b12247a43677","0a9754786c13466ab6e7bcadc7eed5b5","0cabdc2ebbee49e19f0677a483e5e736","de227e0cd5c1469a8e038e2a4ccddf7f","cd17c551e4384f63980eebec23f18190","b415d4f8a08744498d5882e112a14e2a","16273bb0e9b048de80a63ed9ef32cf7a","c0c76d248fc646e1aac79adab29e68d7","e2bfbbe704f5402b9ddcd934881ffefa","2ef7903cf7a0481fa6bc30efc62930f1","40dc3d9801bd45abbe5dc173402fb393","786e4720858a444a996f3f9891b9b0c1","1854263372374fbb973c0b446744e3b8","8850bac428ff4480919526a0c1fd7db1","243992f5abb5427eb1ddb88169ca251c","938162276df94cb9be42ff1ae50f2439","45e3e514d48d4a4c9c6ee6218d0fcb6c","41094c1478554dc8aabe0f1e433f2785","1359ec5804634b1ab1d90892d68e00a8","75629309b7344aee99230a320af2bd3f","4b5235ba89ca4245b924e0041ac5bc5f","4a1f3b50bdf84b3392eecf6744d86221","f91d7cbe64ad423596b70137d23f0275","4ed9df28aa6049ff93f234900a61bbb7","9ea165165a104fefae7f6ace1ee616eb","f56d4d9fe13b4d2e8a8a67ac2e1fc01d","1960887f25d84d07b088fd186456780f","bddda3d36f634eefa3d2856d533fb12d","8934ba939caa41c99dbe02ff5cb256a5","e14bd3b0528149b78fcef6a4cdcc89fb","de8da966211443be94725074fa20f71b","33b203bf82664442ac519334c8895dcb","a18ee82cc1de42758431c2e549cdfb8e","e95c94c3604f47ec825de1fe80e04871","3a398b45a3a841908146f801fcb66e5f","13f7a3ea34ad458eab64abd7c5ca50a3","1ad3cfcc22eb4d4098ad21abc31fed83","a11485ac628943cba051801777d1877b","bfba43846a8141a08da931d96c5c6529","0d32547a760848b295f039849933093c","1c2fce34a4df466baf510b7413825913","71f38db6792a4a7e917dc78ee13786ca","6842fc5adff94725b544ae1ddb0211b1","294edcc1ddde487d97242831a7b159f6"]},"executionInfo":{"status":"ok","timestamp":1709597781535,"user_tz":-120,"elapsed":358697,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"7e1be1f2-1796-4cc6-8756-e08841bde99d"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["model-00001-of-00003.safetensors:   0%|          | 0.00/4.94G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"338ca630e387453d8bf2b12247a43677"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00002-of-00003.safetensors:   0%|          | 0.00/4.95G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"786e4720858a444a996f3f9891b9b0c1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Upload 3 LFS files:   0%|          | 0/3 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f91d7cbe64ad423596b70137d23f0275"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["model-00003-of-00003.safetensors:   0%|          | 0.00/3.59G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e95c94c3604f47ec825de1fe80e04871"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/Elkhayyat17/merged-code-llama2/commit/f9190c589a7aaf05db9be15440365da8cd3d3f95', commit_message='Upload LlamaForCausalLM', commit_description='', oid='f9190c589a7aaf05db9be15440365da8cd3d3f95', pr_url=None, pr_revision=None, pr_num=None)"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["#from google.colab import drive\n","#drive.mount('/content/drive')"],"metadata":{"id":"IbjAqziUyevF","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1708560942384,"user_tz":-120,"elapsed":26939,"user":{"displayName":"احمد السيد ابراهيم ابراهيم الخياط","userId":"08013268120511307501"}},"outputId":"82b1a353-749c-4f84-833d-e091c2b7f8b2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# install necessary libirary to quatization"],"metadata":{"id":"t_wYBKonqCjU"}},{"cell_type":"code","source":["!git clone https://github.com/ggerganov/llama.cpp\n","!cd llama.cpp && git pull && make clean && LLAMA_CUBLAS=1 make\n"],"metadata":{"id":"z21ADbQojzn7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709598007871,"user_tz":-120,"elapsed":226341,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"846e586d-9ce1-4742-8fb9-3d7d55b749ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'llama.cpp'...\n","remote: Enumerating objects: 19725, done.\u001b[K\n","remote: Counting objects: 100% (7040/7040), done.\u001b[K\n","remote: Compressing objects: 100% (597/597), done.\u001b[K\n","remote: Total 19725 (delta 6772), reused 6553 (delta 6440), pack-reused 12685\u001b[K\n","Receiving objects: 100% (19725/19725), 23.58 MiB | 19.08 MiB/s, done.\n","Resolving deltas: 100% (13942/13942), done.\n","Already up to date.\n","I ccache not found. Consider installing it for faster compilation.\n","I llama.cpp build info: \n","I UNAME_S:   Linux\n","I UNAME_P:   x86_64\n","I UNAME_M:   x86_64\n","I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n","I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG \n","I NVCCFLAGS: -std=c++11 -O3 \n","I LDFLAGS:    \n","I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","\n","rm -vrf *.o tests/*.o *.so *.a *.dll benchmark-matmult common/build-info.cpp *.dot *.gcno tests/*.gcno *.gcda tests/*.gcda *.gcov tests/*.gcov lcov-report gcovr-report main quantize quantize-stats perplexity imatrix embedding vdot q8dot train-text-from-scratch convert-llama2c-to-ggml simple batched batched-bench save-load-state server gguf llama-bench libllava.a llava-cli baby-llama beam-search speculative infill tokenize benchmark-matmult parallel finetune export-lora lookahead lookup passkey tests/test-c.o tests/test-llama-grammar tests/test-grammar-parser tests/test-double-float tests/test-grad0 tests/test-opt tests/test-quantize-fns tests/test-quantize-perf tests/test-sampling tests/test-tokenizer-0-llama tests/test-tokenizer-0-falcon tests/test-tokenizer-1-llama tests/test-tokenizer-1-bpe tests/test-rope tests/test-backend-ops tests/test-model-load-cancel tests/test-autorelease\n","find examples pocs -type f -name \"*.o\" -delete\n","I ccache not found. Consider installing it for faster compilation.\n","I llama.cpp build info: \n","I UNAME_S:   Linux\n","I UNAME_P:   x86_64\n","I UNAME_M:   x86_64\n","I CFLAGS:    -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion \n","I CXXFLAGS:  -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include \n","I NVCCFLAGS: -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128 \n","I LDFLAGS:   -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","I CC:        cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","I CXX:       g++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\n","I NVCC:      Build cuda_12.2.r12.2/compiler.33191640_0\n","\n","cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml.c -o ggml.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c llama.cpp -o llama.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/common.cpp -o common.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/sampling.cpp -o sampling.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/grammar-parser.cpp -o grammar-parser.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/build-info.cpp -o build-info.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/console.cpp -o console.o\n","nvcc -std=c++11 -O3 -use_fast_math --forward-unknown-to-host-compiler -arch=native -DGGML_CUDA_DMMV_X=32 -DGGML_CUDA_MMV_Y=1 -DK_QUANTS_PER_ITERATION=2 -DGGML_CUDA_PEER_MAX_BATCH_SIZE=128  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Xcompiler \"-std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -Wno-array-bounds -Wno-format-truncation -Wextra-semi -Wno-pedantic\" -c ggml-cuda.cu -o ggml-cuda.o\n","cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-alloc.c -o ggml-alloc.o\n","cc  -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion    -c ggml-backend.c -o ggml-backend.o\n","cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion     -c ggml-quants.c -o ggml-quants.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/main/main.cpp -o examples/main/main.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o console.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/main/main.o -o main -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","\n","====  Run ./main -h for help.  ====\n","\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/quantize/quantize.cpp -o examples/quantize/quantize.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  build-info.o ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/quantize/quantize.o -o quantize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/quantize-stats/quantize-stats.cpp -o examples/quantize-stats/quantize-stats.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  build-info.o ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/quantize-stats/quantize-stats.o -o quantize-stats -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/perplexity/perplexity.cpp -o examples/perplexity/perplexity.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/perplexity/perplexity.o -o perplexity -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/imatrix/imatrix.cpp -o examples/imatrix/imatrix.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/imatrix/imatrix.o -o imatrix -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/embedding/embedding.cpp -o examples/embedding/embedding.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/embedding/embedding.o -o embedding -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c pocs/vdot/vdot.cpp -o pocs/vdot/vdot.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o pocs/vdot/vdot.o -o vdot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c pocs/vdot/q8dot.cpp -o pocs/vdot/q8dot.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o pocs/vdot/q8dot.o -o q8dot -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c common/train.cpp -o train.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/train-text-from-scratch/train-text-from-scratch.cpp -o examples/train-text-from-scratch/train-text-from-scratch.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/train-text-from-scratch/train-text-from-scratch.o -o train-text-from-scratch -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.cpp -o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/convert-llama2c-to-ggml/convert-llama2c-to-ggml.o -o convert-llama2c-to-ggml -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/simple/simple.cpp -o examples/simple/simple.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/simple/simple.o -o simple -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/batched/batched.cpp -o examples/batched/batched.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/batched/batched.o -o batched -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/batched-bench/batched-bench.cpp -o examples/batched-bench/batched-bench.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  build-info.o ggml.o llama.o common.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/batched-bench/batched-bench.o -o batched-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/save-load-state/save-load-state.cpp -o examples/save-load-state/save-load-state.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/save-load-state/save-load-state.o -o save-load-state -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/server/server.cpp -o examples/server/server.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/llava/clip.cpp -o examples/llava/clip.o -Wno-cast-qual\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -Iexamples/server examples/llava/llava.cpp ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/server/server.o examples/llava/clip.o -o server -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib  \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/gguf/gguf.cpp -o examples/gguf/gguf.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/gguf/gguf.o -o gguf -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/llama-bench/llama-bench.cpp -o examples/llama-bench/llama-bench.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/llama-bench/llama-bench.o -o llama-bench -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -static -fPIC -c examples/llava/llava.cpp -o libllava.a -Wno-cast-qual\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/llava/llava-cli.cpp -o examples/llava/llava-cli.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/llava/clip.cpp  -o examples/llava/clip.o -Wno-cast-qual\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/llava/llava.cpp -o examples/llava/llava.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/llava/llava-cli.o examples/llava/clip.o examples/llava/llava.o -o llava-cli -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/baby-llama/baby-llama.cpp -o examples/baby-llama/baby-llama.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/baby-llama/baby-llama.o -o baby-llama -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/beam-search/beam-search.cpp -o examples/beam-search/beam-search.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/beam-search/beam-search.o -o beam-search -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/speculative/speculative.cpp -o examples/speculative/speculative.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/speculative/speculative.o -o speculative -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/infill/infill.cpp -o examples/infill/infill.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o console.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/infill/infill.o -o infill -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/tokenize/tokenize.cpp -o examples/tokenize/tokenize.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/tokenize/tokenize.o -o tokenize -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/benchmark/benchmark-matmult.cpp -o examples/benchmark/benchmark-matmult.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  build-info.o ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/benchmark/benchmark-matmult.o -o benchmark-matmult -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/parallel/parallel.cpp -o examples/parallel/parallel.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/parallel/parallel.o -o parallel -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/finetune/finetune.cpp -o examples/finetune/finetune.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o train.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/finetune/finetune.o -o finetune -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/export-lora/export-lora.cpp -o examples/export-lora/export-lora.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/export-lora/export-lora.o -o export-lora -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookahead/lookahead.cpp -o examples/lookahead/lookahead.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/lookahead/lookahead.o -o lookahead -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/lookup/lookup.cpp -o examples/lookup/lookup.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/lookup/lookup.o -o lookup -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -c examples/passkey/passkey.cpp -o examples/passkey/passkey.o\n","g++ -std=c++11 -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wmissing-declarations -Wmissing-noreturn -pthread  -march=native -mtune=native -Wno-array-bounds -Wno-format-truncation -Wextra-semi -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  ggml.o llama.o common.o sampling.o grammar-parser.o build-info.o ggml-cuda.o ggml-alloc.o ggml-backend.o ggml-quants.o examples/passkey/passkey.o -o passkey -lcuda -lcublas -lculibos -lcudart -lcublasLt -lpthread -ldl -lrt -L/usr/local/cuda/lib64 -L/usr/lib64 -L/usr/local/cuda/targets/x86_64-linux/lib -L/usr/lib/wsl/lib \n","cc -I. -Icommon -D_XOPEN_SOURCE=600 -D_GNU_SOURCE -DNDEBUG -DGGML_USE_CUBLAS -I/usr/local/cuda/include -I/usr/local/cuda/targets/x86_64-linux/include  -std=c11   -fPIC -O3 -Wall -Wextra -Wpedantic -Wcast-qual -Wno-unused-function -Wshadow -Wstrict-prototypes -Wpointer-arith -Wmissing-prototypes -Werror=implicit-int -Werror=implicit-function-declaration -pthread -march=native -mtune=native -Wdouble-promotion  -c tests/test-c.c -o tests/test-c.o\n","\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: '/llama.cpp/requirements.txt'\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":["!pip install  -U 'numpy~=1.24.4 ' 'sentencepiece~=0.1.98' 'transformers>=4.35.2,<5.0.0' 'gguf>=0.1.0' 'protobuf>=4.21.0,<5.0.0'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":896},"id":"vxEQBCYo_bDl","executionInfo":{"status":"ok","timestamp":1709598456178,"user_tz":-120,"elapsed":29792,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"a84994cb-f524-404b-f8fb-67eae2665a1e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting numpy~=1.24.4\n","  Downloading numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sentencepiece~=0.1.98 in /usr/local/lib/python3.10/dist-packages (0.1.99)\n","Requirement already satisfied: transformers<5.0.0,>=4.35.2 in /usr/local/lib/python3.10/dist-packages (4.38.1)\n","Collecting transformers<5.0.0,>=4.35.2\n","  Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m94.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting gguf>=0.1.0\n","  Downloading gguf-0.6.0-py3-none-any.whl (23 kB)\n","Collecting protobuf<5.0.0,>=4.21.0\n","  Downloading protobuf-4.25.3-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.6/294.6 kB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (3.13.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (0.20.3)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (6.0.1)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (2023.12.25)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (2.31.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (0.15.2)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (0.4.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.35.2) (4.66.2)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers<5.0.0,>=4.35.2) (2023.6.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers<5.0.0,>=4.35.2) (4.10.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<5.0.0,>=4.35.2) (2024.2.2)\n","Installing collected packages: protobuf, numpy, gguf, transformers\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","  Attempting uninstall: numpy\n","    Found existing installation: numpy 1.25.2\n","    Uninstalling numpy-1.25.2:\n","      Successfully uninstalled numpy-1.25.2\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.38.1\n","    Uninstalling transformers-4.38.1:\n","      Successfully uninstalled transformers-4.38.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","tensorflow-metadata 1.14.0 requires protobuf<4.21,>=3.20.3, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed gguf-0.6.0 numpy-1.24.4 protobuf-4.25.3 transformers-4.38.2\n"]},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["numpy","transformers"]},"id":"d13ec48fefad46668c84da2dd29b462f"}},"metadata":{}}]},{"cell_type":"markdown","source":["Be sure current directory is llama.cpp"],"metadata":{"id":"ZNDoO3dpBPSe"}},{"cell_type":"code","source":["#%cd llama.cpp"],"metadata":{"id":"047o4ImVA-Fw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!python3 llama.cpp/convert.py  /content/merged\n"],"metadata":{"execution":{"iopub.status.busy":"2024-02-15T01:34:01.627446Z","iopub.execute_input":"2024-02-15T01:34:01.628387Z","iopub.status.idle":"2024-02-15T01:35:19.576841Z","shell.execute_reply.started":"2024-02-15T01:34:01.628329Z","shell.execute_reply":"2024-02-15T01:35:19.575730Z"},"trusted":true,"id":"IaeINkQ0bona","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709598614942,"user_tz":-120,"elapsed":147360,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"367652de-8562-4ed4-f261-23b7939cfe35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Loading model file /content/merged/model-00001-of-00003.safetensors\n","Loading model file /content/merged/model-00001-of-00003.safetensors\n","Loading model file /content/merged/model-00002-of-00003.safetensors\n","Loading model file /content/merged/model-00003-of-00003.safetensors\n","params = Params(n_vocab=32000, n_embd=4096, n_layer=32, n_ctx=4096, n_ff=11008, n_head=32, n_head_kv=32, n_experts=None, n_experts_used=None, f_norm_eps=1e-05, rope_scaling_type=None, f_rope_freq_base=10000.0, f_rope_scale=None, n_orig_ctx=None, rope_finetuned=None, ftype=None, path_model=PosixPath('/content/merged'))\n","Found vocab files: {'spm': PosixPath('/content/merged/tokenizer.model'), 'bpe': None, 'hfft': PosixPath('/content/merged/tokenizer.json')}\n","Loading vocab file PosixPath('/content/merged/tokenizer.model'), type 'spm'\n","Vocab info: <SentencePieceVocab with 32000 base tokens and 0 added tokens>\n","Special vocab info: <SpecialVocab with 0 merges, special tokens {'bos': 1, 'eos': 2, 'unk': 0}, add special tokens {'bos': True, 'eos': False}>\n","Permuting layer 0\n","Permuting layer 1\n","Permuting layer 2\n","Permuting layer 3\n","Permuting layer 4\n","Permuting layer 5\n","Permuting layer 6\n","Permuting layer 7\n","Permuting layer 8\n","Permuting layer 9\n","Permuting layer 10\n","Permuting layer 11\n","Permuting layer 12\n","Permuting layer 13\n","Permuting layer 14\n","Permuting layer 15\n","Permuting layer 16\n","Permuting layer 17\n","Permuting layer 18\n","Permuting layer 19\n","Permuting layer 20\n","Permuting layer 21\n","Permuting layer 22\n","Permuting layer 23\n","Permuting layer 24\n","Permuting layer 25\n","Permuting layer 26\n","Permuting layer 27\n","Permuting layer 28\n","Permuting layer 29\n","Permuting layer 30\n","Permuting layer 31\n","model.embed_tokens.weight                        -> token_embd.weight                        | F16    | [32000, 4096]\n","model.layers.0.input_layernorm.weight            -> blk.0.attn_norm.weight                   | F16    | [4096]\n","model.layers.0.mlp.down_proj.weight              -> blk.0.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.0.mlp.gate_proj.weight              -> blk.0.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.0.mlp.up_proj.weight                -> blk.0.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.0.post_attention_layernorm.weight   -> blk.0.ffn_norm.weight                    | F16    | [4096]\n","model.layers.0.self_attn.k_proj.weight           -> blk.0.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.0.self_attn.o_proj.weight           -> blk.0.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.0.self_attn.q_proj.weight           -> blk.0.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.0.self_attn.v_proj.weight           -> blk.0.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.1.input_layernorm.weight            -> blk.1.attn_norm.weight                   | F16    | [4096]\n","model.layers.1.mlp.down_proj.weight              -> blk.1.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.1.mlp.gate_proj.weight              -> blk.1.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.1.mlp.up_proj.weight                -> blk.1.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.1.post_attention_layernorm.weight   -> blk.1.ffn_norm.weight                    | F16    | [4096]\n","model.layers.1.self_attn.k_proj.weight           -> blk.1.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.1.self_attn.o_proj.weight           -> blk.1.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.1.self_attn.q_proj.weight           -> blk.1.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.1.self_attn.v_proj.weight           -> blk.1.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.10.input_layernorm.weight           -> blk.10.attn_norm.weight                  | F16    | [4096]\n","model.layers.10.mlp.down_proj.weight             -> blk.10.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.10.mlp.gate_proj.weight             -> blk.10.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.10.mlp.up_proj.weight               -> blk.10.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.10.post_attention_layernorm.weight  -> blk.10.ffn_norm.weight                   | F16    | [4096]\n","model.layers.10.self_attn.k_proj.weight          -> blk.10.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.10.self_attn.o_proj.weight          -> blk.10.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.10.self_attn.q_proj.weight          -> blk.10.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.10.self_attn.v_proj.weight          -> blk.10.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.11.mlp.gate_proj.weight             -> blk.11.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.11.self_attn.k_proj.weight          -> blk.11.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.11.self_attn.o_proj.weight          -> blk.11.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.11.self_attn.q_proj.weight          -> blk.11.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.11.self_attn.v_proj.weight          -> blk.11.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.2.input_layernorm.weight            -> blk.2.attn_norm.weight                   | F16    | [4096]\n","model.layers.2.mlp.down_proj.weight              -> blk.2.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.2.mlp.gate_proj.weight              -> blk.2.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.2.mlp.up_proj.weight                -> blk.2.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.2.post_attention_layernorm.weight   -> blk.2.ffn_norm.weight                    | F16    | [4096]\n","model.layers.2.self_attn.k_proj.weight           -> blk.2.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.2.self_attn.o_proj.weight           -> blk.2.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.2.self_attn.q_proj.weight           -> blk.2.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.2.self_attn.v_proj.weight           -> blk.2.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.3.input_layernorm.weight            -> blk.3.attn_norm.weight                   | F16    | [4096]\n","model.layers.3.mlp.down_proj.weight              -> blk.3.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.3.mlp.gate_proj.weight              -> blk.3.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.3.mlp.up_proj.weight                -> blk.3.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.3.post_attention_layernorm.weight   -> blk.3.ffn_norm.weight                    | F16    | [4096]\n","model.layers.3.self_attn.k_proj.weight           -> blk.3.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.3.self_attn.o_proj.weight           -> blk.3.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.3.self_attn.q_proj.weight           -> blk.3.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.3.self_attn.v_proj.weight           -> blk.3.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.4.input_layernorm.weight            -> blk.4.attn_norm.weight                   | F16    | [4096]\n","model.layers.4.mlp.down_proj.weight              -> blk.4.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.4.mlp.gate_proj.weight              -> blk.4.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.4.mlp.up_proj.weight                -> blk.4.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.4.post_attention_layernorm.weight   -> blk.4.ffn_norm.weight                    | F16    | [4096]\n","model.layers.4.self_attn.k_proj.weight           -> blk.4.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.4.self_attn.o_proj.weight           -> blk.4.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.4.self_attn.q_proj.weight           -> blk.4.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.4.self_attn.v_proj.weight           -> blk.4.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.5.input_layernorm.weight            -> blk.5.attn_norm.weight                   | F16    | [4096]\n","model.layers.5.mlp.down_proj.weight              -> blk.5.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.5.mlp.gate_proj.weight              -> blk.5.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.5.mlp.up_proj.weight                -> blk.5.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.5.post_attention_layernorm.weight   -> blk.5.ffn_norm.weight                    | F16    | [4096]\n","model.layers.5.self_attn.k_proj.weight           -> blk.5.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.5.self_attn.o_proj.weight           -> blk.5.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.5.self_attn.q_proj.weight           -> blk.5.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.5.self_attn.v_proj.weight           -> blk.5.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.6.input_layernorm.weight            -> blk.6.attn_norm.weight                   | F16    | [4096]\n","model.layers.6.mlp.down_proj.weight              -> blk.6.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.6.mlp.gate_proj.weight              -> blk.6.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.6.mlp.up_proj.weight                -> blk.6.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.6.post_attention_layernorm.weight   -> blk.6.ffn_norm.weight                    | F16    | [4096]\n","model.layers.6.self_attn.k_proj.weight           -> blk.6.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.6.self_attn.o_proj.weight           -> blk.6.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.6.self_attn.q_proj.weight           -> blk.6.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.6.self_attn.v_proj.weight           -> blk.6.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.7.input_layernorm.weight            -> blk.7.attn_norm.weight                   | F16    | [4096]\n","model.layers.7.mlp.down_proj.weight              -> blk.7.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.7.mlp.gate_proj.weight              -> blk.7.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.7.mlp.up_proj.weight                -> blk.7.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.7.post_attention_layernorm.weight   -> blk.7.ffn_norm.weight                    | F16    | [4096]\n","model.layers.7.self_attn.k_proj.weight           -> blk.7.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.7.self_attn.o_proj.weight           -> blk.7.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.7.self_attn.q_proj.weight           -> blk.7.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.7.self_attn.v_proj.weight           -> blk.7.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.8.input_layernorm.weight            -> blk.8.attn_norm.weight                   | F16    | [4096]\n","model.layers.8.mlp.down_proj.weight              -> blk.8.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.8.mlp.gate_proj.weight              -> blk.8.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.8.mlp.up_proj.weight                -> blk.8.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.8.post_attention_layernorm.weight   -> blk.8.ffn_norm.weight                    | F16    | [4096]\n","model.layers.8.self_attn.k_proj.weight           -> blk.8.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.8.self_attn.o_proj.weight           -> blk.8.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.8.self_attn.q_proj.weight           -> blk.8.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.8.self_attn.v_proj.weight           -> blk.8.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.9.input_layernorm.weight            -> blk.9.attn_norm.weight                   | F16    | [4096]\n","model.layers.9.mlp.down_proj.weight              -> blk.9.ffn_down.weight                    | F16    | [4096, 11008]\n","model.layers.9.mlp.gate_proj.weight              -> blk.9.ffn_gate.weight                    | F16    | [11008, 4096]\n","model.layers.9.mlp.up_proj.weight                -> blk.9.ffn_up.weight                      | F16    | [11008, 4096]\n","model.layers.9.post_attention_layernorm.weight   -> blk.9.ffn_norm.weight                    | F16    | [4096]\n","model.layers.9.self_attn.k_proj.weight           -> blk.9.attn_k.weight                      | F16    | [4096, 4096]\n","model.layers.9.self_attn.o_proj.weight           -> blk.9.attn_output.weight                 | F16    | [4096, 4096]\n","model.layers.9.self_attn.q_proj.weight           -> blk.9.attn_q.weight                      | F16    | [4096, 4096]\n","model.layers.9.self_attn.v_proj.weight           -> blk.9.attn_v.weight                      | F16    | [4096, 4096]\n","model.layers.11.input_layernorm.weight           -> blk.11.attn_norm.weight                  | F16    | [4096]\n","model.layers.11.mlp.down_proj.weight             -> blk.11.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.11.mlp.up_proj.weight               -> blk.11.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.11.post_attention_layernorm.weight  -> blk.11.ffn_norm.weight                   | F16    | [4096]\n","model.layers.12.input_layernorm.weight           -> blk.12.attn_norm.weight                  | F16    | [4096]\n","model.layers.12.mlp.down_proj.weight             -> blk.12.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.12.mlp.gate_proj.weight             -> blk.12.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.12.mlp.up_proj.weight               -> blk.12.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.12.post_attention_layernorm.weight  -> blk.12.ffn_norm.weight                   | F16    | [4096]\n","model.layers.12.self_attn.k_proj.weight          -> blk.12.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.12.self_attn.o_proj.weight          -> blk.12.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.12.self_attn.q_proj.weight          -> blk.12.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.12.self_attn.v_proj.weight          -> blk.12.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.13.input_layernorm.weight           -> blk.13.attn_norm.weight                  | F16    | [4096]\n","model.layers.13.mlp.down_proj.weight             -> blk.13.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.13.mlp.gate_proj.weight             -> blk.13.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.13.mlp.up_proj.weight               -> blk.13.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.13.post_attention_layernorm.weight  -> blk.13.ffn_norm.weight                   | F16    | [4096]\n","model.layers.13.self_attn.k_proj.weight          -> blk.13.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.13.self_attn.o_proj.weight          -> blk.13.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.13.self_attn.q_proj.weight          -> blk.13.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.13.self_attn.v_proj.weight          -> blk.13.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.14.input_layernorm.weight           -> blk.14.attn_norm.weight                  | F16    | [4096]\n","model.layers.14.mlp.down_proj.weight             -> blk.14.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.14.mlp.gate_proj.weight             -> blk.14.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.14.mlp.up_proj.weight               -> blk.14.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.14.post_attention_layernorm.weight  -> blk.14.ffn_norm.weight                   | F16    | [4096]\n","model.layers.14.self_attn.k_proj.weight          -> blk.14.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.14.self_attn.o_proj.weight          -> blk.14.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.14.self_attn.q_proj.weight          -> blk.14.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.14.self_attn.v_proj.weight          -> blk.14.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.15.input_layernorm.weight           -> blk.15.attn_norm.weight                  | F16    | [4096]\n","model.layers.15.mlp.down_proj.weight             -> blk.15.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.15.mlp.gate_proj.weight             -> blk.15.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.15.mlp.up_proj.weight               -> blk.15.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.15.post_attention_layernorm.weight  -> blk.15.ffn_norm.weight                   | F16    | [4096]\n","model.layers.15.self_attn.k_proj.weight          -> blk.15.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.15.self_attn.o_proj.weight          -> blk.15.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.15.self_attn.q_proj.weight          -> blk.15.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.15.self_attn.v_proj.weight          -> blk.15.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.16.input_layernorm.weight           -> blk.16.attn_norm.weight                  | F16    | [4096]\n","model.layers.16.mlp.down_proj.weight             -> blk.16.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.16.mlp.gate_proj.weight             -> blk.16.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.16.mlp.up_proj.weight               -> blk.16.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.16.post_attention_layernorm.weight  -> blk.16.ffn_norm.weight                   | F16    | [4096]\n","model.layers.16.self_attn.k_proj.weight          -> blk.16.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.16.self_attn.o_proj.weight          -> blk.16.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.16.self_attn.q_proj.weight          -> blk.16.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.16.self_attn.v_proj.weight          -> blk.16.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.17.input_layernorm.weight           -> blk.17.attn_norm.weight                  | F16    | [4096]\n","model.layers.17.mlp.down_proj.weight             -> blk.17.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.17.mlp.gate_proj.weight             -> blk.17.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.17.mlp.up_proj.weight               -> blk.17.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.17.post_attention_layernorm.weight  -> blk.17.ffn_norm.weight                   | F16    | [4096]\n","model.layers.17.self_attn.k_proj.weight          -> blk.17.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.17.self_attn.o_proj.weight          -> blk.17.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.17.self_attn.q_proj.weight          -> blk.17.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.17.self_attn.v_proj.weight          -> blk.17.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.18.input_layernorm.weight           -> blk.18.attn_norm.weight                  | F16    | [4096]\n","model.layers.18.mlp.down_proj.weight             -> blk.18.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.18.mlp.gate_proj.weight             -> blk.18.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.18.mlp.up_proj.weight               -> blk.18.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.18.post_attention_layernorm.weight  -> blk.18.ffn_norm.weight                   | F16    | [4096]\n","model.layers.18.self_attn.k_proj.weight          -> blk.18.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.18.self_attn.o_proj.weight          -> blk.18.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.18.self_attn.q_proj.weight          -> blk.18.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.18.self_attn.v_proj.weight          -> blk.18.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.19.input_layernorm.weight           -> blk.19.attn_norm.weight                  | F16    | [4096]\n","model.layers.19.mlp.down_proj.weight             -> blk.19.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.19.mlp.gate_proj.weight             -> blk.19.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.19.mlp.up_proj.weight               -> blk.19.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.19.post_attention_layernorm.weight  -> blk.19.ffn_norm.weight                   | F16    | [4096]\n","model.layers.19.self_attn.k_proj.weight          -> blk.19.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.19.self_attn.o_proj.weight          -> blk.19.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.19.self_attn.q_proj.weight          -> blk.19.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.19.self_attn.v_proj.weight          -> blk.19.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.20.input_layernorm.weight           -> blk.20.attn_norm.weight                  | F16    | [4096]\n","model.layers.20.mlp.down_proj.weight             -> blk.20.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.20.mlp.gate_proj.weight             -> blk.20.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.20.mlp.up_proj.weight               -> blk.20.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.20.post_attention_layernorm.weight  -> blk.20.ffn_norm.weight                   | F16    | [4096]\n","model.layers.20.self_attn.k_proj.weight          -> blk.20.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.20.self_attn.o_proj.weight          -> blk.20.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.20.self_attn.q_proj.weight          -> blk.20.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.20.self_attn.v_proj.weight          -> blk.20.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.21.input_layernorm.weight           -> blk.21.attn_norm.weight                  | F16    | [4096]\n","model.layers.21.mlp.down_proj.weight             -> blk.21.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.21.mlp.gate_proj.weight             -> blk.21.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.21.mlp.up_proj.weight               -> blk.21.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.21.post_attention_layernorm.weight  -> blk.21.ffn_norm.weight                   | F16    | [4096]\n","model.layers.21.self_attn.k_proj.weight          -> blk.21.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.21.self_attn.o_proj.weight          -> blk.21.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.21.self_attn.q_proj.weight          -> blk.21.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.21.self_attn.v_proj.weight          -> blk.21.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.22.input_layernorm.weight           -> blk.22.attn_norm.weight                  | F16    | [4096]\n","model.layers.22.mlp.down_proj.weight             -> blk.22.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.22.mlp.gate_proj.weight             -> blk.22.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.22.mlp.up_proj.weight               -> blk.22.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.22.post_attention_layernorm.weight  -> blk.22.ffn_norm.weight                   | F16    | [4096]\n","model.layers.22.self_attn.k_proj.weight          -> blk.22.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.22.self_attn.o_proj.weight          -> blk.22.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.22.self_attn.q_proj.weight          -> blk.22.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.22.self_attn.v_proj.weight          -> blk.22.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.23.mlp.gate_proj.weight             -> blk.23.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.23.mlp.up_proj.weight               -> blk.23.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.23.self_attn.k_proj.weight          -> blk.23.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.23.self_attn.o_proj.weight          -> blk.23.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.23.self_attn.q_proj.weight          -> blk.23.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.23.self_attn.v_proj.weight          -> blk.23.attn_v.weight                     | F16    | [4096, 4096]\n","lm_head.weight                                   -> output.weight                            | F16    | [32000, 4096]\n","model.layers.23.input_layernorm.weight           -> blk.23.attn_norm.weight                  | F16    | [4096]\n","model.layers.23.mlp.down_proj.weight             -> blk.23.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.23.post_attention_layernorm.weight  -> blk.23.ffn_norm.weight                   | F16    | [4096]\n","model.layers.24.input_layernorm.weight           -> blk.24.attn_norm.weight                  | F16    | [4096]\n","model.layers.24.mlp.down_proj.weight             -> blk.24.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.24.mlp.gate_proj.weight             -> blk.24.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.24.mlp.up_proj.weight               -> blk.24.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.24.post_attention_layernorm.weight  -> blk.24.ffn_norm.weight                   | F16    | [4096]\n","model.layers.24.self_attn.k_proj.weight          -> blk.24.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.24.self_attn.o_proj.weight          -> blk.24.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.24.self_attn.q_proj.weight          -> blk.24.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.24.self_attn.v_proj.weight          -> blk.24.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.25.input_layernorm.weight           -> blk.25.attn_norm.weight                  | F16    | [4096]\n","model.layers.25.mlp.down_proj.weight             -> blk.25.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.25.mlp.gate_proj.weight             -> blk.25.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.25.mlp.up_proj.weight               -> blk.25.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.25.post_attention_layernorm.weight  -> blk.25.ffn_norm.weight                   | F16    | [4096]\n","model.layers.25.self_attn.k_proj.weight          -> blk.25.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.25.self_attn.o_proj.weight          -> blk.25.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.25.self_attn.q_proj.weight          -> blk.25.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.25.self_attn.v_proj.weight          -> blk.25.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.26.input_layernorm.weight           -> blk.26.attn_norm.weight                  | F16    | [4096]\n","model.layers.26.mlp.down_proj.weight             -> blk.26.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.26.mlp.gate_proj.weight             -> blk.26.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.26.mlp.up_proj.weight               -> blk.26.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.26.post_attention_layernorm.weight  -> blk.26.ffn_norm.weight                   | F16    | [4096]\n","model.layers.26.self_attn.k_proj.weight          -> blk.26.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.26.self_attn.o_proj.weight          -> blk.26.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.26.self_attn.q_proj.weight          -> blk.26.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.26.self_attn.v_proj.weight          -> blk.26.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.27.input_layernorm.weight           -> blk.27.attn_norm.weight                  | F16    | [4096]\n","model.layers.27.mlp.down_proj.weight             -> blk.27.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.27.mlp.gate_proj.weight             -> blk.27.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.27.mlp.up_proj.weight               -> blk.27.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.27.post_attention_layernorm.weight  -> blk.27.ffn_norm.weight                   | F16    | [4096]\n","model.layers.27.self_attn.k_proj.weight          -> blk.27.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.27.self_attn.o_proj.weight          -> blk.27.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.27.self_attn.q_proj.weight          -> blk.27.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.27.self_attn.v_proj.weight          -> blk.27.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.28.input_layernorm.weight           -> blk.28.attn_norm.weight                  | F16    | [4096]\n","model.layers.28.mlp.down_proj.weight             -> blk.28.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.28.mlp.gate_proj.weight             -> blk.28.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.28.mlp.up_proj.weight               -> blk.28.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.28.post_attention_layernorm.weight  -> blk.28.ffn_norm.weight                   | F16    | [4096]\n","model.layers.28.self_attn.k_proj.weight          -> blk.28.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.28.self_attn.o_proj.weight          -> blk.28.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.28.self_attn.q_proj.weight          -> blk.28.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.28.self_attn.v_proj.weight          -> blk.28.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.29.input_layernorm.weight           -> blk.29.attn_norm.weight                  | F16    | [4096]\n","model.layers.29.mlp.down_proj.weight             -> blk.29.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.29.mlp.gate_proj.weight             -> blk.29.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.29.mlp.up_proj.weight               -> blk.29.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.29.post_attention_layernorm.weight  -> blk.29.ffn_norm.weight                   | F16    | [4096]\n","model.layers.29.self_attn.k_proj.weight          -> blk.29.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.29.self_attn.o_proj.weight          -> blk.29.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.29.self_attn.q_proj.weight          -> blk.29.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.29.self_attn.v_proj.weight          -> blk.29.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.30.input_layernorm.weight           -> blk.30.attn_norm.weight                  | F16    | [4096]\n","model.layers.30.mlp.down_proj.weight             -> blk.30.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.30.mlp.gate_proj.weight             -> blk.30.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.30.mlp.up_proj.weight               -> blk.30.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.30.post_attention_layernorm.weight  -> blk.30.ffn_norm.weight                   | F16    | [4096]\n","model.layers.30.self_attn.k_proj.weight          -> blk.30.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.30.self_attn.o_proj.weight          -> blk.30.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.30.self_attn.q_proj.weight          -> blk.30.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.30.self_attn.v_proj.weight          -> blk.30.attn_v.weight                     | F16    | [4096, 4096]\n","model.layers.31.input_layernorm.weight           -> blk.31.attn_norm.weight                  | F16    | [4096]\n","model.layers.31.mlp.down_proj.weight             -> blk.31.ffn_down.weight                   | F16    | [4096, 11008]\n","model.layers.31.mlp.gate_proj.weight             -> blk.31.ffn_gate.weight                   | F16    | [11008, 4096]\n","model.layers.31.mlp.up_proj.weight               -> blk.31.ffn_up.weight                     | F16    | [11008, 4096]\n","model.layers.31.post_attention_layernorm.weight  -> blk.31.ffn_norm.weight                   | F16    | [4096]\n","model.layers.31.self_attn.k_proj.weight          -> blk.31.attn_k.weight                     | F16    | [4096, 4096]\n","model.layers.31.self_attn.o_proj.weight          -> blk.31.attn_output.weight                | F16    | [4096, 4096]\n","model.layers.31.self_attn.q_proj.weight          -> blk.31.attn_q.weight                     | F16    | [4096, 4096]\n","model.layers.31.self_attn.v_proj.weight          -> blk.31.attn_v.weight                     | F16    | [4096, 4096]\n","model.norm.weight                                -> output_norm.weight                       | F16    | [4096]\n","Writing /content/merged/ggml-model-f16.gguf, format 1\n","Ignoring added_tokens.json since model matches vocab size without it.\n","gguf: This GGUF file is for Little Endian only\n","gguf: Setting special token type bos to 1\n","gguf: Setting special token type eos to 2\n","gguf: Setting special token type unk to 0\n","gguf: Setting add_bos_token to True\n","gguf: Setting add_eos_token to False\n","gguf: Setting chat_template to {% if messages[0]['role'] == 'system' %}{% set loop_messages = messages[1:] %}{% set system_message = messages[0]['content'] %}{% else %}{% set loop_messages = messages %}{% set system_message = false %}{% endif %}{% for message in loop_messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if loop.index0 == 0 and system_message != false %}{% set content = '<<SYS>>\\n' + system_message + '\\n<</SYS>>\\n\\n' + message['content'] %}{% else %}{% set content = message['content'] %}{% endif %}{% if message['role'] == 'user' %}{{ bos_token + '[INST] ' + content.strip() + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ ' '  + content.strip() + ' ' + eos_token }}{% endif %}{% endfor %}\n","[  1/291] Writing tensor token_embd.weight                      | size  32000 x   4096  | type F16  | T+   2\n","[  2/291] Writing tensor blk.0.attn_norm.weight                 | size   4096           | type F32  | T+   3\n","[  3/291] Writing tensor blk.0.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+   3\n","[  4/291] Writing tensor blk.0.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+   3\n","[  5/291] Writing tensor blk.0.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+   4\n","[  6/291] Writing tensor blk.0.ffn_norm.weight                  | size   4096           | type F32  | T+   4\n","[  7/291] Writing tensor blk.0.attn_k.weight                    | size   4096 x   4096  | type F16  | T+   4\n","[  8/291] Writing tensor blk.0.attn_output.weight               | size   4096 x   4096  | type F16  | T+   4\n","[  9/291] Writing tensor blk.0.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   4\n","[ 10/291] Writing tensor blk.0.attn_v.weight                    | size   4096 x   4096  | type F16  | T+   4\n","[ 11/291] Writing tensor blk.1.attn_norm.weight                 | size   4096           | type F32  | T+   4\n","[ 12/291] Writing tensor blk.1.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+   5\n","[ 13/291] Writing tensor blk.1.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+   5\n","[ 14/291] Writing tensor blk.1.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+   5\n","[ 15/291] Writing tensor blk.1.ffn_norm.weight                  | size   4096           | type F32  | T+   5\n","[ 16/291] Writing tensor blk.1.attn_k.weight                    | size   4096 x   4096  | type F16  | T+   5\n","[ 17/291] Writing tensor blk.1.attn_output.weight               | size   4096 x   4096  | type F16  | T+   6\n","[ 18/291] Writing tensor blk.1.attn_q.weight                    | size   4096 x   4096  | type F16  | T+   6\n","[ 19/291] Writing tensor blk.1.attn_v.weight                    | size   4096 x   4096  | type F16  | T+   6\n","[ 20/291] Writing tensor blk.10.attn_norm.weight                | size   4096           | type F32  | T+   6\n","[ 21/291] Writing tensor blk.10.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+   7\n","[ 22/291] Writing tensor blk.10.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+   7\n","[ 23/291] Writing tensor blk.10.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+   7\n","[ 24/291] Writing tensor blk.10.ffn_norm.weight                 | size   4096           | type F32  | T+   8\n","[ 25/291] Writing tensor blk.10.attn_k.weight                   | size   4096 x   4096  | type F16  | T+   8\n","[ 26/291] Writing tensor blk.10.attn_output.weight              | size   4096 x   4096  | type F16  | T+   8\n","[ 27/291] Writing tensor blk.10.attn_q.weight                   | size   4096 x   4096  | type F16  | T+   8\n","[ 28/291] Writing tensor blk.10.attn_v.weight                   | size   4096 x   4096  | type F16  | T+   8\n","[ 29/291] Writing tensor blk.11.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+   8\n","[ 30/291] Writing tensor blk.11.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  13\n","[ 31/291] Writing tensor blk.11.attn_output.weight              | size   4096 x   4096  | type F16  | T+  13\n","[ 32/291] Writing tensor blk.11.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  13\n","[ 33/291] Writing tensor blk.11.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  13\n","[ 34/291] Writing tensor blk.2.attn_norm.weight                 | size   4096           | type F32  | T+  13\n","[ 35/291] Writing tensor blk.2.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  13\n","[ 36/291] Writing tensor blk.2.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  14\n","[ 37/291] Writing tensor blk.2.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  14\n","[ 38/291] Writing tensor blk.2.ffn_norm.weight                  | size   4096           | type F32  | T+  14\n","[ 39/291] Writing tensor blk.2.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  14\n","[ 40/291] Writing tensor blk.2.attn_output.weight               | size   4096 x   4096  | type F16  | T+  14\n","[ 41/291] Writing tensor blk.2.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  14\n","[ 42/291] Writing tensor blk.2.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  15\n","[ 43/291] Writing tensor blk.3.attn_norm.weight                 | size   4096           | type F32  | T+  15\n","[ 44/291] Writing tensor blk.3.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  15\n","[ 45/291] Writing tensor blk.3.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  16\n","[ 46/291] Writing tensor blk.3.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  16\n","[ 47/291] Writing tensor blk.3.ffn_norm.weight                  | size   4096           | type F32  | T+  18\n","[ 48/291] Writing tensor blk.3.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  18\n","[ 49/291] Writing tensor blk.3.attn_output.weight               | size   4096 x   4096  | type F16  | T+  18\n","[ 50/291] Writing tensor blk.3.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  18\n","[ 51/291] Writing tensor blk.3.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  18\n","[ 52/291] Writing tensor blk.4.attn_norm.weight                 | size   4096           | type F32  | T+  18\n","[ 53/291] Writing tensor blk.4.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  18\n","[ 54/291] Writing tensor blk.4.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  23\n","[ 55/291] Writing tensor blk.4.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  23\n","[ 56/291] Writing tensor blk.4.ffn_norm.weight                  | size   4096           | type F32  | T+  28\n","[ 57/291] Writing tensor blk.4.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  28\n","[ 58/291] Writing tensor blk.4.attn_output.weight               | size   4096 x   4096  | type F16  | T+  28\n","[ 59/291] Writing tensor blk.4.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  28\n","[ 60/291] Writing tensor blk.4.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  28\n","[ 61/291] Writing tensor blk.5.attn_norm.weight                 | size   4096           | type F32  | T+  28\n","[ 62/291] Writing tensor blk.5.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  28\n","[ 63/291] Writing tensor blk.5.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  33\n","[ 64/291] Writing tensor blk.5.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  33\n","[ 65/291] Writing tensor blk.5.ffn_norm.weight                  | size   4096           | type F32  | T+  33\n","[ 66/291] Writing tensor blk.5.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  33\n","[ 67/291] Writing tensor blk.5.attn_output.weight               | size   4096 x   4096  | type F16  | T+  34\n","[ 68/291] Writing tensor blk.5.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  34\n","[ 69/291] Writing tensor blk.5.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  34\n","[ 70/291] Writing tensor blk.6.attn_norm.weight                 | size   4096           | type F32  | T+  34\n","[ 71/291] Writing tensor blk.6.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  34\n","[ 72/291] Writing tensor blk.6.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  35\n","[ 73/291] Writing tensor blk.6.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  35\n","[ 74/291] Writing tensor blk.6.ffn_norm.weight                  | size   4096           | type F32  | T+  37\n","[ 75/291] Writing tensor blk.6.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  37\n","[ 76/291] Writing tensor blk.6.attn_output.weight               | size   4096 x   4096  | type F16  | T+  38\n","[ 77/291] Writing tensor blk.6.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  38\n","[ 78/291] Writing tensor blk.6.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  38\n","[ 79/291] Writing tensor blk.7.attn_norm.weight                 | size   4096           | type F32  | T+  38\n","[ 80/291] Writing tensor blk.7.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  38\n","[ 81/291] Writing tensor blk.7.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  39\n","[ 82/291] Writing tensor blk.7.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  39\n","[ 83/291] Writing tensor blk.7.ffn_norm.weight                  | size   4096           | type F32  | T+  39\n","[ 84/291] Writing tensor blk.7.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  39\n","[ 85/291] Writing tensor blk.7.attn_output.weight               | size   4096 x   4096  | type F16  | T+  40\n","[ 86/291] Writing tensor blk.7.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  40\n","[ 87/291] Writing tensor blk.7.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  40\n","[ 88/291] Writing tensor blk.8.attn_norm.weight                 | size   4096           | type F32  | T+  40\n","[ 89/291] Writing tensor blk.8.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  41\n","[ 90/291] Writing tensor blk.8.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  41\n","[ 91/291] Writing tensor blk.8.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  41\n","[ 92/291] Writing tensor blk.8.ffn_norm.weight                  | size   4096           | type F32  | T+  43\n","[ 93/291] Writing tensor blk.8.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  43\n","[ 94/291] Writing tensor blk.8.attn_output.weight               | size   4096 x   4096  | type F16  | T+  43\n","[ 95/291] Writing tensor blk.8.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  43\n","[ 96/291] Writing tensor blk.8.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  43\n","[ 97/291] Writing tensor blk.9.attn_norm.weight                 | size   4096           | type F32  | T+  44\n","[ 98/291] Writing tensor blk.9.ffn_down.weight                  | size   4096 x  11008  | type F16  | T+  44\n","[ 99/291] Writing tensor blk.9.ffn_gate.weight                  | size  11008 x   4096  | type F16  | T+  44\n","[100/291] Writing tensor blk.9.ffn_up.weight                    | size  11008 x   4096  | type F16  | T+  44\n","[101/291] Writing tensor blk.9.ffn_norm.weight                  | size   4096           | type F32  | T+  48\n","[102/291] Writing tensor blk.9.attn_k.weight                    | size   4096 x   4096  | type F16  | T+  48\n","[103/291] Writing tensor blk.9.attn_output.weight               | size   4096 x   4096  | type F16  | T+  48\n","[104/291] Writing tensor blk.9.attn_q.weight                    | size   4096 x   4096  | type F16  | T+  48\n","[105/291] Writing tensor blk.9.attn_v.weight                    | size   4096 x   4096  | type F16  | T+  48\n","[106/291] Writing tensor blk.11.attn_norm.weight                | size   4096           | type F32  | T+  48\n","[107/291] Writing tensor blk.11.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  48\n","[108/291] Writing tensor blk.11.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  49\n","[109/291] Writing tensor blk.11.ffn_norm.weight                 | size   4096           | type F32  | T+  49\n","[110/291] Writing tensor blk.12.attn_norm.weight                | size   4096           | type F32  | T+  49\n","[111/291] Writing tensor blk.12.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  50\n","[112/291] Writing tensor blk.12.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  50\n","[113/291] Writing tensor blk.12.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  53\n","[114/291] Writing tensor blk.12.ffn_norm.weight                 | size   4096           | type F32  | T+  54\n","[115/291] Writing tensor blk.12.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  54\n","[116/291] Writing tensor blk.12.attn_output.weight              | size   4096 x   4096  | type F16  | T+  54\n","[117/291] Writing tensor blk.12.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  54\n","[118/291] Writing tensor blk.12.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  54\n","[119/291] Writing tensor blk.13.attn_norm.weight                | size   4096           | type F32  | T+  54\n","[120/291] Writing tensor blk.13.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  54\n","[121/291] Writing tensor blk.13.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  58\n","[122/291] Writing tensor blk.13.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  59\n","[123/291] Writing tensor blk.13.ffn_norm.weight                 | size   4096           | type F32  | T+  59\n","[124/291] Writing tensor blk.13.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  59\n","[125/291] Writing tensor blk.13.attn_output.weight              | size   4096 x   4096  | type F16  | T+  63\n","[126/291] Writing tensor blk.13.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  63\n","[127/291] Writing tensor blk.13.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  64\n","[128/291] Writing tensor blk.14.attn_norm.weight                | size   4096           | type F32  | T+  64\n","[129/291] Writing tensor blk.14.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  64\n","[130/291] Writing tensor blk.14.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  64\n","[131/291] Writing tensor blk.14.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  64\n","[132/291] Writing tensor blk.14.ffn_norm.weight                 | size   4096           | type F32  | T+  65\n","[133/291] Writing tensor blk.14.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  65\n","[134/291] Writing tensor blk.14.attn_output.weight              | size   4096 x   4096  | type F16  | T+  65\n","[135/291] Writing tensor blk.14.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  66\n","[136/291] Writing tensor blk.14.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  66\n","[137/291] Writing tensor blk.15.attn_norm.weight                | size   4096           | type F32  | T+  66\n","[138/291] Writing tensor blk.15.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  67\n","[139/291] Writing tensor blk.15.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  67\n","[140/291] Writing tensor blk.15.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  68\n","[141/291] Writing tensor blk.15.ffn_norm.weight                 | size   4096           | type F32  | T+  69\n","[142/291] Writing tensor blk.15.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  69\n","[143/291] Writing tensor blk.15.attn_output.weight              | size   4096 x   4096  | type F16  | T+  69\n","[144/291] Writing tensor blk.15.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  69\n","[145/291] Writing tensor blk.15.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  70\n","[146/291] Writing tensor blk.16.attn_norm.weight                | size   4096           | type F32  | T+  73\n","[147/291] Writing tensor blk.16.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  73\n","[148/291] Writing tensor blk.16.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  74\n","[149/291] Writing tensor blk.16.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  74\n","[150/291] Writing tensor blk.16.ffn_norm.weight                 | size   4096           | type F32  | T+  75\n","[151/291] Writing tensor blk.16.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  75\n","[152/291] Writing tensor blk.16.attn_output.weight              | size   4096 x   4096  | type F16  | T+  75\n","[153/291] Writing tensor blk.16.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  75\n","[154/291] Writing tensor blk.16.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  75\n","[155/291] Writing tensor blk.17.attn_norm.weight                | size   4096           | type F32  | T+  75\n","[156/291] Writing tensor blk.17.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  76\n","[157/291] Writing tensor blk.17.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  77\n","[158/291] Writing tensor blk.17.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  78\n","[159/291] Writing tensor blk.17.ffn_norm.weight                 | size   4096           | type F32  | T+  78\n","[160/291] Writing tensor blk.17.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  78\n","[161/291] Writing tensor blk.17.attn_output.weight              | size   4096 x   4096  | type F16  | T+  79\n","[162/291] Writing tensor blk.17.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  79\n","[163/291] Writing tensor blk.17.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  79\n","[164/291] Writing tensor blk.18.attn_norm.weight                | size   4096           | type F32  | T+  79\n","[165/291] Writing tensor blk.18.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  79\n","[166/291] Writing tensor blk.18.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  79\n","[167/291] Writing tensor blk.18.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  80\n","[168/291] Writing tensor blk.18.ffn_norm.weight                 | size   4096           | type F32  | T+  81\n","[169/291] Writing tensor blk.18.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  81\n","[170/291] Writing tensor blk.18.attn_output.weight              | size   4096 x   4096  | type F16  | T+  81\n","[171/291] Writing tensor blk.18.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  83\n","[172/291] Writing tensor blk.18.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  83\n","[173/291] Writing tensor blk.19.attn_norm.weight                | size   4096           | type F32  | T+  84\n","[174/291] Writing tensor blk.19.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  84\n","[175/291] Writing tensor blk.19.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  84\n","[176/291] Writing tensor blk.19.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  89\n","[177/291] Writing tensor blk.19.ffn_norm.weight                 | size   4096           | type F32  | T+  90\n","[178/291] Writing tensor blk.19.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  90\n","[179/291] Writing tensor blk.19.attn_output.weight              | size   4096 x   4096  | type F16  | T+  90\n","[180/291] Writing tensor blk.19.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  93\n","[181/291] Writing tensor blk.19.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  94\n","[182/291] Writing tensor blk.20.attn_norm.weight                | size   4096           | type F32  | T+  94\n","[183/291] Writing tensor blk.20.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  94\n","[184/291] Writing tensor blk.20.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  95\n","[185/291] Writing tensor blk.20.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+  95\n","[186/291] Writing tensor blk.20.ffn_norm.weight                 | size   4096           | type F32  | T+  95\n","[187/291] Writing tensor blk.20.attn_k.weight                   | size   4096 x   4096  | type F16  | T+  95\n","[188/291] Writing tensor blk.20.attn_output.weight              | size   4096 x   4096  | type F16  | T+  98\n","[189/291] Writing tensor blk.20.attn_q.weight                   | size   4096 x   4096  | type F16  | T+  99\n","[190/291] Writing tensor blk.20.attn_v.weight                   | size   4096 x   4096  | type F16  | T+  99\n","[191/291] Writing tensor blk.21.attn_norm.weight                | size   4096           | type F32  | T+  99\n","[192/291] Writing tensor blk.21.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+  99\n","[193/291] Writing tensor blk.21.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+  99\n","[194/291] Writing tensor blk.21.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 100\n","[195/291] Writing tensor blk.21.ffn_norm.weight                 | size   4096           | type F32  | T+ 104\n","[196/291] Writing tensor blk.21.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 104\n","[197/291] Writing tensor blk.21.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 104\n","[198/291] Writing tensor blk.21.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 104\n","[199/291] Writing tensor blk.21.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 104\n","[200/291] Writing tensor blk.22.attn_norm.weight                | size   4096           | type F32  | T+ 105\n","[201/291] Writing tensor blk.22.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 105\n","[202/291] Writing tensor blk.22.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 105\n","[203/291] Writing tensor blk.22.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 106\n","[204/291] Writing tensor blk.22.ffn_norm.weight                 | size   4096           | type F32  | T+ 106\n","[205/291] Writing tensor blk.22.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 106\n","[206/291] Writing tensor blk.22.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 106\n","[207/291] Writing tensor blk.22.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 107\n","[208/291] Writing tensor blk.22.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 108\n","[209/291] Writing tensor blk.23.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 110\n","[210/291] Writing tensor blk.23.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 110\n","[211/291] Writing tensor blk.23.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 110\n","[212/291] Writing tensor blk.23.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 110\n","[213/291] Writing tensor blk.23.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 110\n","[214/291] Writing tensor blk.23.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 110\n","[215/291] Writing tensor output.weight                          | size  32000 x   4096  | type F16  | T+ 113\n","[216/291] Writing tensor blk.23.attn_norm.weight                | size   4096           | type F32  | T+ 113\n","[217/291] Writing tensor blk.23.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 113\n","[218/291] Writing tensor blk.23.ffn_norm.weight                 | size   4096           | type F32  | T+ 114\n","[219/291] Writing tensor blk.24.attn_norm.weight                | size   4096           | type F32  | T+ 114\n","[220/291] Writing tensor blk.24.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 114\n","[221/291] Writing tensor blk.24.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 114\n","[222/291] Writing tensor blk.24.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 114\n","[223/291] Writing tensor blk.24.ffn_norm.weight                 | size   4096           | type F32  | T+ 115\n","[224/291] Writing tensor blk.24.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 116\n","[225/291] Writing tensor blk.24.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 116\n","[226/291] Writing tensor blk.24.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 116\n","[227/291] Writing tensor blk.24.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 116\n","[228/291] Writing tensor blk.25.attn_norm.weight                | size   4096           | type F32  | T+ 116\n","[229/291] Writing tensor blk.25.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 119\n","[230/291] Writing tensor blk.25.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 119\n","[231/291] Writing tensor blk.25.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 120\n","[232/291] Writing tensor blk.25.ffn_norm.weight                 | size   4096           | type F32  | T+ 123\n","[233/291] Writing tensor blk.25.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 123\n","[234/291] Writing tensor blk.25.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 123\n","[235/291] Writing tensor blk.25.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 124\n","[236/291] Writing tensor blk.25.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 124\n","[237/291] Writing tensor blk.26.attn_norm.weight                | size   4096           | type F32  | T+ 124\n","[238/291] Writing tensor blk.26.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 124\n","[239/291] Writing tensor blk.26.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 124\n","[240/291] Writing tensor blk.26.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 124\n","[241/291] Writing tensor blk.26.ffn_norm.weight                 | size   4096           | type F32  | T+ 125\n","[242/291] Writing tensor blk.26.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 125\n","[243/291] Writing tensor blk.26.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 125\n","[244/291] Writing tensor blk.26.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 125\n","[245/291] Writing tensor blk.26.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 125\n","[246/291] Writing tensor blk.27.attn_norm.weight                | size   4096           | type F32  | T+ 125\n","[247/291] Writing tensor blk.27.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 126\n","[248/291] Writing tensor blk.27.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 127\n","[249/291] Writing tensor blk.27.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 127\n","[250/291] Writing tensor blk.27.ffn_norm.weight                 | size   4096           | type F32  | T+ 129\n","[251/291] Writing tensor blk.27.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 129\n","[252/291] Writing tensor blk.27.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 129\n","[253/291] Writing tensor blk.27.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 129\n","[254/291] Writing tensor blk.27.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 129\n","[255/291] Writing tensor blk.28.attn_norm.weight                | size   4096           | type F32  | T+ 129\n","[256/291] Writing tensor blk.28.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 129\n","[257/291] Writing tensor blk.28.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 134\n","[258/291] Writing tensor blk.28.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 134\n","[259/291] Writing tensor blk.28.ffn_norm.weight                 | size   4096           | type F32  | T+ 134\n","[260/291] Writing tensor blk.28.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 134\n","[261/291] Writing tensor blk.28.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 135\n","[262/291] Writing tensor blk.28.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 135\n","[263/291] Writing tensor blk.28.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 135\n","[264/291] Writing tensor blk.29.attn_norm.weight                | size   4096           | type F32  | T+ 135\n","[265/291] Writing tensor blk.29.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 135\n","[266/291] Writing tensor blk.29.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 136\n","[267/291] Writing tensor blk.29.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 136\n","[268/291] Writing tensor blk.29.ffn_norm.weight                 | size   4096           | type F32  | T+ 137\n","[269/291] Writing tensor blk.29.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 137\n","[270/291] Writing tensor blk.29.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 138\n","[271/291] Writing tensor blk.29.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 138\n","[272/291] Writing tensor blk.29.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 138\n","[273/291] Writing tensor blk.30.attn_norm.weight                | size   4096           | type F32  | T+ 139\n","[274/291] Writing tensor blk.30.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 139\n","[275/291] Writing tensor blk.30.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 139\n","[276/291] Writing tensor blk.30.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 139\n","[277/291] Writing tensor blk.30.ffn_norm.weight                 | size   4096           | type F32  | T+ 139\n","[278/291] Writing tensor blk.30.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 139\n","[279/291] Writing tensor blk.30.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 140\n","[280/291] Writing tensor blk.30.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 140\n","[281/291] Writing tensor blk.30.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 140\n","[282/291] Writing tensor blk.31.attn_norm.weight                | size   4096           | type F32  | T+ 140\n","[283/291] Writing tensor blk.31.ffn_down.weight                 | size   4096 x  11008  | type F16  | T+ 141\n","[284/291] Writing tensor blk.31.ffn_gate.weight                 | size  11008 x   4096  | type F16  | T+ 141\n","[285/291] Writing tensor blk.31.ffn_up.weight                   | size  11008 x   4096  | type F16  | T+ 141\n","[286/291] Writing tensor blk.31.ffn_norm.weight                 | size   4096           | type F32  | T+ 144\n","[287/291] Writing tensor blk.31.attn_k.weight                   | size   4096 x   4096  | type F16  | T+ 144\n","[288/291] Writing tensor blk.31.attn_output.weight              | size   4096 x   4096  | type F16  | T+ 144\n","[289/291] Writing tensor blk.31.attn_q.weight                   | size   4096 x   4096  | type F16  | T+ 144\n","[290/291] Writing tensor blk.31.attn_v.weight                   | size   4096 x   4096  | type F16  | T+ 144\n","[291/291] Writing tensor output_norm.weight                     | size   4096           | type F32  | T+ 144\n","Wrote /content/merged/ggml-model-f16.gguf\n"]}]},{"cell_type":"code","source":["!./llama.cpp/quantize /content/merged/ggml-model-f16.gguf code-llama2-Q4_K_M.gguf Q4_K_M\n"],"metadata":{"id":"nWadML3FbonZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1709599434736,"user_tz":-120,"elapsed":812463,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"0e664cf0-0491-4b08-ef1d-29afdd2d8ef4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ggml_init_cublas: GGML_CUDA_FORCE_MMQ:   no\n","ggml_init_cublas: CUDA_USE_TENSOR_CORES: yes\n","ggml_init_cublas: found 1 CUDA devices:\n","  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n","main: build = 2341 (29ae62d2)\n","main: built with cc (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0 for x86_64-linux-gnu\n","main: quantizing '/content/merged/ggml-model-f16.gguf' to 'code-llama2-Q4_K_M.gguf' as Q4_K_M\n","llama_model_loader: loaded meta data with 22 key-value pairs and 291 tensors from /content/merged/ggml-model-f16.gguf (version GGUF V3 (latest))\n","llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n","llama_model_loader: - kv   0:                       general.architecture str              = llama\n","llama_model_loader: - kv   1:                               general.name str              = LLaMA v2\n","llama_model_loader: - kv   2:                       llama.context_length u32              = 4096\n","llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n","llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n","llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n","llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n","llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n","llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n","llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n","llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n","llama_model_loader: - kv  11:                          general.file_type u32              = 1\n","llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n","llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n","llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n","llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n","llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n","llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n","llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n","llama_model_loader: - kv  19:               tokenizer.ggml.add_bos_token bool             = true\n","llama_model_loader: - kv  20:               tokenizer.ggml.add_eos_token bool             = false\n","llama_model_loader: - kv  21:                    tokenizer.chat_template str              = {% if messages[0]['role'] == 'system'...\n","llama_model_loader: - type  f32:   65 tensors\n","llama_model_loader: - type  f16:  226 tensors\n","llama_model_quantize_internal: meta size = 742016 bytes\n","[   1/ 291]                    token_embd.weight - [ 4096, 32000,     1,     1], type =    f16, quantizing to q4_K .. size =   250.00 MiB ->    70.31 MiB\n","[   2/ 291]               blk.0.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[   3/ 291]                blk.0.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[   4/ 291]                blk.0.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[   5/ 291]                  blk.0.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[   6/ 291]                blk.0.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[   7/ 291]                  blk.0.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[   8/ 291]             blk.0.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[   9/ 291]                  blk.0.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  10/ 291]                  blk.0.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  11/ 291]               blk.1.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  12/ 291]                blk.1.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[  13/ 291]                blk.1.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  14/ 291]                  blk.1.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  15/ 291]                blk.1.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  16/ 291]                  blk.1.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  17/ 291]             blk.1.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  18/ 291]                  blk.1.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  19/ 291]                  blk.1.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  20/ 291]              blk.10.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  21/ 291]               blk.10.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[  22/ 291]               blk.10.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  23/ 291]                 blk.10.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  24/ 291]               blk.10.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  25/ 291]                 blk.10.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  26/ 291]            blk.10.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  27/ 291]                 blk.10.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  28/ 291]                 blk.10.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  29/ 291]               blk.11.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  30/ 291]                 blk.11.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  31/ 291]            blk.11.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  32/ 291]                 blk.11.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  33/ 291]                 blk.11.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  34/ 291]               blk.2.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  35/ 291]                blk.2.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[  36/ 291]                blk.2.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  37/ 291]                  blk.2.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  38/ 291]                blk.2.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  39/ 291]                  blk.2.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  40/ 291]             blk.2.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  41/ 291]                  blk.2.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  42/ 291]                  blk.2.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  43/ 291]               blk.3.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  44/ 291]                blk.3.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  45/ 291]                blk.3.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  46/ 291]                  blk.3.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  47/ 291]                blk.3.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  48/ 291]                  blk.3.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  49/ 291]             blk.3.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  50/ 291]                  blk.3.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  51/ 291]                  blk.3.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  52/ 291]               blk.4.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  53/ 291]                blk.4.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  54/ 291]                blk.4.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  55/ 291]                  blk.4.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  56/ 291]                blk.4.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  57/ 291]                  blk.4.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  58/ 291]             blk.4.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  59/ 291]                  blk.4.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  60/ 291]                  blk.4.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  61/ 291]               blk.5.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  62/ 291]                blk.5.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[  63/ 291]                blk.5.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  64/ 291]                  blk.5.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  65/ 291]                blk.5.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  66/ 291]                  blk.5.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  67/ 291]             blk.5.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  68/ 291]                  blk.5.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  69/ 291]                  blk.5.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  70/ 291]               blk.6.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  71/ 291]                blk.6.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  72/ 291]                blk.6.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  73/ 291]                  blk.6.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  74/ 291]                blk.6.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  75/ 291]                  blk.6.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  76/ 291]             blk.6.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  77/ 291]                  blk.6.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  78/ 291]                  blk.6.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  79/ 291]               blk.7.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  80/ 291]                blk.7.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  81/ 291]                blk.7.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  82/ 291]                  blk.7.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  83/ 291]                blk.7.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  84/ 291]                  blk.7.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  85/ 291]             blk.7.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  86/ 291]                  blk.7.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  87/ 291]                  blk.7.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[  88/ 291]               blk.8.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  89/ 291]                blk.8.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[  90/ 291]                blk.8.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  91/ 291]                  blk.8.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  92/ 291]                blk.8.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  93/ 291]                  blk.8.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  94/ 291]             blk.8.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  95/ 291]                  blk.8.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  96/ 291]                  blk.8.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[  97/ 291]               blk.9.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[  98/ 291]                blk.9.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[  99/ 291]                blk.9.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 100/ 291]                  blk.9.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 101/ 291]                blk.9.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 102/ 291]                  blk.9.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 103/ 291]             blk.9.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 104/ 291]                  blk.9.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 105/ 291]                  blk.9.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 106/ 291]              blk.11.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 107/ 291]               blk.11.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 108/ 291]                 blk.11.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 109/ 291]               blk.11.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 110/ 291]              blk.12.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 111/ 291]               blk.12.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 112/ 291]               blk.12.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 113/ 291]                 blk.12.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 114/ 291]               blk.12.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 115/ 291]                 blk.12.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 116/ 291]            blk.12.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 117/ 291]                 blk.12.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 118/ 291]                 blk.12.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 119/ 291]              blk.13.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 120/ 291]               blk.13.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 121/ 291]               blk.13.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 122/ 291]                 blk.13.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 123/ 291]               blk.13.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 124/ 291]                 blk.13.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 125/ 291]            blk.13.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 126/ 291]                 blk.13.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 127/ 291]                 blk.13.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 128/ 291]              blk.14.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 129/ 291]               blk.14.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 130/ 291]               blk.14.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 131/ 291]                 blk.14.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 132/ 291]               blk.14.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 133/ 291]                 blk.14.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 134/ 291]            blk.14.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 135/ 291]                 blk.14.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 136/ 291]                 blk.14.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 137/ 291]              blk.15.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 138/ 291]               blk.15.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 139/ 291]               blk.15.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 140/ 291]                 blk.15.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 141/ 291]               blk.15.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 142/ 291]                 blk.15.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 143/ 291]            blk.15.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 144/ 291]                 blk.15.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 145/ 291]                 blk.15.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 146/ 291]              blk.16.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 147/ 291]               blk.16.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 148/ 291]               blk.16.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 149/ 291]                 blk.16.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 150/ 291]               blk.16.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 151/ 291]                 blk.16.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 152/ 291]            blk.16.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 153/ 291]                 blk.16.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 154/ 291]                 blk.16.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 155/ 291]              blk.17.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 156/ 291]               blk.17.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 157/ 291]               blk.17.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 158/ 291]                 blk.17.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 159/ 291]               blk.17.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 160/ 291]                 blk.17.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 161/ 291]            blk.17.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 162/ 291]                 blk.17.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 163/ 291]                 blk.17.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 164/ 291]              blk.18.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 165/ 291]               blk.18.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 166/ 291]               blk.18.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 167/ 291]                 blk.18.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 168/ 291]               blk.18.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 169/ 291]                 blk.18.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 170/ 291]            blk.18.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 171/ 291]                 blk.18.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 172/ 291]                 blk.18.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 173/ 291]              blk.19.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 174/ 291]               blk.19.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 175/ 291]               blk.19.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 176/ 291]                 blk.19.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 177/ 291]               blk.19.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 178/ 291]                 blk.19.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 179/ 291]            blk.19.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 180/ 291]                 blk.19.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 181/ 291]                 blk.19.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 182/ 291]              blk.20.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 183/ 291]               blk.20.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 184/ 291]               blk.20.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 185/ 291]                 blk.20.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 186/ 291]               blk.20.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 187/ 291]                 blk.20.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 188/ 291]            blk.20.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 189/ 291]                 blk.20.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 190/ 291]                 blk.20.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 191/ 291]              blk.21.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 192/ 291]               blk.21.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 193/ 291]               blk.21.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 194/ 291]                 blk.21.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 195/ 291]               blk.21.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 196/ 291]                 blk.21.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 197/ 291]            blk.21.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 198/ 291]                 blk.21.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 199/ 291]                 blk.21.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 200/ 291]              blk.22.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 201/ 291]               blk.22.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 202/ 291]               blk.22.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 203/ 291]                 blk.22.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 204/ 291]               blk.22.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 205/ 291]                 blk.22.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 206/ 291]            blk.22.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 207/ 291]                 blk.22.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 208/ 291]                 blk.22.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 209/ 291]               blk.23.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 210/ 291]                 blk.23.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 211/ 291]                 blk.23.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 212/ 291]            blk.23.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 213/ 291]                 blk.23.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 214/ 291]                 blk.23.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 215/ 291]                        output.weight - [ 4096, 32000,     1,     1], type =    f16, quantizing to q6_K .. size =   250.00 MiB ->   102.54 MiB\n","[ 216/ 291]              blk.23.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 217/ 291]               blk.23.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 218/ 291]               blk.23.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 219/ 291]              blk.24.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 220/ 291]               blk.24.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 221/ 291]               blk.24.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 222/ 291]                 blk.24.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 223/ 291]               blk.24.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 224/ 291]                 blk.24.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 225/ 291]            blk.24.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 226/ 291]                 blk.24.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 227/ 291]                 blk.24.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 228/ 291]              blk.25.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 229/ 291]               blk.25.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 230/ 291]               blk.25.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 231/ 291]                 blk.25.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 232/ 291]               blk.25.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 233/ 291]                 blk.25.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 234/ 291]            blk.25.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 235/ 291]                 blk.25.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 236/ 291]                 blk.25.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 237/ 291]              blk.26.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 238/ 291]               blk.26.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 239/ 291]               blk.26.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 240/ 291]                 blk.26.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 241/ 291]               blk.26.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 242/ 291]                 blk.26.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 243/ 291]            blk.26.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 244/ 291]                 blk.26.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 245/ 291]                 blk.26.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 246/ 291]              blk.27.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 247/ 291]               blk.27.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 248/ 291]               blk.27.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 249/ 291]                 blk.27.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 250/ 291]               blk.27.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 251/ 291]                 blk.27.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 252/ 291]            blk.27.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 253/ 291]                 blk.27.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 254/ 291]                 blk.27.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 255/ 291]              blk.28.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 256/ 291]               blk.28.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 257/ 291]               blk.28.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 258/ 291]                 blk.28.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 259/ 291]               blk.28.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 260/ 291]                 blk.28.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 261/ 291]            blk.28.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 262/ 291]                 blk.28.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 263/ 291]                 blk.28.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 264/ 291]              blk.29.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 265/ 291]               blk.29.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 266/ 291]               blk.29.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 267/ 291]                 blk.29.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 268/ 291]               blk.29.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 269/ 291]                 blk.29.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 270/ 291]            blk.29.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 271/ 291]                 blk.29.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 272/ 291]                 blk.29.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 273/ 291]              blk.30.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 274/ 291]               blk.30.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 275/ 291]               blk.30.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 276/ 291]                 blk.30.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 277/ 291]               blk.30.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 278/ 291]                 blk.30.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 279/ 291]            blk.30.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 280/ 291]                 blk.30.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 281/ 291]                 blk.30.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 282/ 291]              blk.31.attn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 283/ 291]               blk.31.ffn_down.weight - [11008,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    86.00 MiB ->    35.27 MiB\n","[ 284/ 291]               blk.31.ffn_gate.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 285/ 291]                 blk.31.ffn_up.weight - [ 4096, 11008,     1,     1], type =    f16, quantizing to q4_K .. size =    86.00 MiB ->    24.19 MiB\n","[ 286/ 291]               blk.31.ffn_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","[ 287/ 291]                 blk.31.attn_k.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 288/ 291]            blk.31.attn_output.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 289/ 291]                 blk.31.attn_q.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q4_K .. size =    32.00 MiB ->     9.00 MiB\n","[ 290/ 291]                 blk.31.attn_v.weight - [ 4096,  4096,     1,     1], type =    f16, quantizing to q6_K .. size =    32.00 MiB ->    13.12 MiB\n","[ 291/ 291]                   output_norm.weight - [ 4096,     1,     1,     1], type =    f32, size =    0.016 MB\n","llama_model_quantize_internal: model size  = 12853.02 MB\n","llama_model_quantize_internal: quant size  =  3891.24 MB\n","\n","main: quantize time = 811207.33 ms\n","main:    total time = 811207.33 ms\n"]}]},{"cell_type":"markdown","source":["# Upload quatizatoin file to HF"],"metadata":{"id":"rYSoOhd2qq-7"}},{"cell_type":"markdown","source":["copy gguf file path"],"metadata":{"id":"ALxGkRx-B4o9"}},{"cell_type":"markdown","source":["![image.png](data:image/png;base64,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)"],"metadata":{"id":"D7d6BTTRB0eS"}},{"cell_type":"code","source":["\n","from huggingface_hub import login\n","login()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["b8141f60a027495d9dca6b1891726832","60168be8ba854d299e1d7a73a0904f08","08dc8d15fe624335b756a864a856e151","ee00a02258e2464785cad6122b324ace","d4f5b2ac123c4ca08be9a94ffad53b29","8e799d2aadab4c20a5e5752162bf5ee5","798e3f26e0d14bff94f2c5240ede4ac1","88a88a2c4a55414aafa1b536cb62479d","5ee89c6d1f1247f0a56763496032b4d1","a5e3724a95f34dff988fd2ba3381ffb3","cad476cc27ea4f05800f2b51e2b2816f","ab5a64e958f048bc91f29dc96f82a10e","b5091fcdd5df4aa491a9775836f69a50","3f94cec911184cb1abd87ffc3c68f898","4b0e6e7ed95f4a4c81aaf45153ad0c38","7e926a5e61444777b31c941e8722e112","d8d91753de43484fa9ff40e71377c6bb","d5cac79a28a142deb898fba5e778cbbb","141c8420cd334c7aacfead039e2550c3","d93b6d6aa2d9429283b0bbab1a10720a","a602512e878c4dc29bb6cf2d54f6d385","2a43a44ff1c44b9d8987606a8d453027","aa8797ddf70447f791fd1a9ab10ee834","0d7ff6c27b2049ec980b6c0730afb735","04353fe66ef6468495a22d542526c4e6","db3a6c25c4da49b59f93f9fbe483fafd","c8c030dc028e46689e14f3c194635612","f9a5dfcf6a0e4848a0143c023bef1e8a","386b6d6d906b4bee96628e11c2f3b181","eb5a3de45b31415c8c75396b0148dd3b","20171f924a374721a633313cf619d5d1","8581e93dd4cd41a995deb122b3abebd4"]},"id":"QbAbdcB3rbkG","executionInfo":{"status":"ok","timestamp":1709599487815,"user_tz":-120,"elapsed":294,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"a920e3bd-fbbd-47f1-b0bc-b648faa7f0ee"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b8141f60a027495d9dca6b1891726832"}},"metadata":{}}]},{"cell_type":"code","source":["#Create repo first manullay or coding\n","#here i created it manullay then past id\n","from huggingface_hub import HfApi\n","api = HfApi()\n","api.upload_file(\n","    path_or_fileobj=\"/content/code-llama2-Q4_K_M.gguf\", ## fil  path\n","    path_in_repo=\"code-llama2-Q4_K_M.gguf\", ## file name\n","    repo_id=\"Elkhayyat17/code-llama2-gguf\",## repi id\n","    repo_type=\"model\",\n",")"],"metadata":{"trusted":true,"id":"O4b0vvJxbonb","colab":{"base_uri":"https://localhost:8080/","height":118,"referenced_widgets":["6ee6ee2a6bef45db82f4350799bbb2e0","bc3116b8bf3d407f93438bb826ec1b59","201ba60d566f49b9975522e57c564c22","6a869e085224498082c136920b2bcfcc","565aa8a47a2a4626b75121b9203f3cf3","5f3053bb1ae74b70970c8246f7ff2d79","a4d1994c20874f4cb7cb18d7b3515544","c488be7fc1b3475cb97859b49b39e21d","2f253a0de7ea4715ac69eb35c458e45f","8fd6c024292647329aacd440d4e5d432","a061cecabe064444b04a4c94dab75953"]},"executionInfo":{"status":"ok","timestamp":1709599676596,"user_tz":-120,"elapsed":141369,"user":{"displayName":"Ahmed Elkhayyat","userId":"12405653964529109374"}},"outputId":"48f6bfb2-9cd9-430e-df24-b0506fdc3631"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["code-llama2-Q4_K_M.gguf:   0%|          | 0.00/4.08G [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ee6ee2a6bef45db82f4350799bbb2e0"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["CommitInfo(commit_url='https://huggingface.co/Elkhayyat17/code-llama2-gguf/commit/a21cc99537bd855dbb76e76795058cb4d73d847f', commit_message='Upload code-llama2-Q4_K_M.gguf with huggingface_hub', commit_description='', oid='a21cc99537bd855dbb76e76795058cb4d73d847f', pr_url=None, pr_revision=None, pr_num=None)"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":24}]}]}